{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version 10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "!cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgl-cu100 in /usr/local/lib/python3.6/dist-packages (0.4.3.post2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu100) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu100) (1.17.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl-cu100) (2.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl-cu100) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu100) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu100) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu100) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl-cu100) (1.25.8)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl-cu100) (4.4.0)\n",
      "Requirement already satisfied: torchtext==0.3.1 in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (1.17.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (4.42.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (1.4.0+cu92)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2.9)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.17.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.25.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2019.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl-cu100\n",
    "# !pip install dgl\n",
    "!pip install torchtext==0.3.1\n",
    "# !pip install torchtext==0.5.0\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch.conv as conv\n",
    "import dgl.nn.pytorch.glob as glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "from torchtext import data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import init\n",
    "from dgl.nn.pytorch.softmax import edge_softmax\n",
    "\n",
    "os.environ['DGLBACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/storage/slu/atis/'\n",
    "# path = '/storage/slu/snips/'\n",
    "train_path = path + 'train.csv'\n",
    "dev_path = path + 'dev.csv'\n",
    "test_path = path + 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. take a look at the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>slot</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to fly from baltimore to dallas round trip</td>\n",
       "      <td>O O O O O B-fromloc.city_name O B-toloc.city_n...</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round trip fares from baltimore to philadelphi...</td>\n",
       "      <td>B-round_trip I-round_trip O O B-fromloc.city_n...</td>\n",
       "      <td>atis_airfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show me the flights arriving on baltimore on j...</td>\n",
       "      <td>O O O O O O B-toloc.city_name O B-arrive_date....</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the flights which depart from san fra...</td>\n",
       "      <td>O O O O O O O B-fromloc.city_name I-fromloc.ci...</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which airlines fly from boston to washington d...</td>\n",
       "      <td>O O O O B-fromloc.city_name O B-toloc.city_nam...</td>\n",
       "      <td>atis_airline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  i want to fly from baltimore to dallas round trip   \n",
       "1  round trip fares from baltimore to philadelphi...   \n",
       "2  show me the flights arriving on baltimore on j...   \n",
       "3  what are the flights which depart from san fra...   \n",
       "4  which airlines fly from boston to washington d...   \n",
       "\n",
       "                                                slot        intent  \n",
       "0  O O O O O B-fromloc.city_name O B-toloc.city_n...   atis_flight  \n",
       "1  B-round_trip I-round_trip O O B-fromloc.city_n...  atis_airfare  \n",
       "2  O O O O O O B-toloc.city_name O B-arrive_date....   atis_flight  \n",
       "3  O O O O O O O B-fromloc.city_name I-fromloc.ci...   atis_flight  \n",
       "4  O O O O B-fromloc.city_name O B-toloc.city_nam...  atis_airline  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. is cuda available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'); device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "random_state = 2020\n",
    "# Fix the random seed of package random.\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Fix the random seed of Pytorch when using CPU.\n",
    "torch.manual_seed(random_state)\n",
    "torch.random.manual_seed(random_state)\n",
    "\n",
    "dgl.random.seed(random_state)\n",
    "\n",
    "# Fix the random seed of Pytorch when using GPU.\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.is_available())\n",
    "    torch.cuda.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed_all(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. preprocessing data using torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here here',\n",
       " 'here we',\n",
       " 'here are',\n",
       " 'here me',\n",
       " 'we here',\n",
       " 'we we',\n",
       " 'we are',\n",
       " 'we me',\n",
       " 'are here',\n",
       " 'are we',\n",
       " 'are are',\n",
       " 'are me',\n",
       " 'me here',\n",
       " 'me we',\n",
       " 'me are',\n",
       " 'me me']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 4\n",
    "def text_edge_tokenize(x):\n",
    "    x = x.split()\n",
    "    res = []\n",
    "    for i in range(len(x)):\n",
    "        for j in range(max(0, i-window_size), min(i+window_size+1, len(x))):\n",
    "#             if i != j:\n",
    "            res.append(str(x[i] + ' ' + str(x[j])))\n",
    "    return res\n",
    "sentence = 'here we are me'\n",
    "text_edge_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0, 4, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4]\n",
      "[4, 0, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "window_size = 11\n",
    "def text_edge_tokenize(x):\n",
    "    src = [0, len(x)-1]\n",
    "    dst = [len(x)-1, 0]\n",
    "    for i in range(len(x)):\n",
    "        for j in range(max(0, i-window_size), min(i+window_size+1, len(x))):\n",
    "#             if i != j:\n",
    "            src.append(i)\n",
    "            dst.append(j)\n",
    "    return src, dst\n",
    "sentence = np.arange(5)\n",
    "print(sentence)\n",
    "src, dst = text_edge_tokenize(sentence)\n",
    "print(src)\n",
    "print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(batch_first=True, lower=True, include_lengths=True)\n",
    "SLOT_LABEL = data.Field(batch_first=True, is_target=True, include_lengths=True, pad_token=None, unk_token=None)\n",
    "# SLOT_LABEL = data.Field(batch_first=True, is_target=True, include_lengths=True)\n",
    "INTENT_LABEL = data.Field(batch_first=True, is_target=True, pad_token=None, unk_token=None)\n",
    "# INTENT_LABEL = data.Field(batch_first=True, is_target=True, pad_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text', TEXT), ('slot', SLOT_LABEL), ('intent', INTENT_LABEL)]\n",
    "# fields = {\n",
    "#     'text': ('text1', TEXT),\n",
    "#     'edge': ('edge1', TEXT_EDGE),\n",
    "#     'slot': ('slot1', SLOT_LABEL),\n",
    "#     'intent': ('intent1', INTENT_LABEL)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = data.TabularDataset.splits(\n",
    "    path=path,\n",
    "    format='csv',\n",
    "    train=train_path,\n",
    "    validation=dev_path,\n",
    "    test=test_path,\n",
    "    skip_header=True,\n",
    "    fields=fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT.build_vocab(train, vectors='glove.6B.300d')\n",
    "TEXT.build_vocab(train)\n",
    "SLOT_LABEL.build_vocab(train)\n",
    "INTENT_LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, val, test),\n",
    "    batch_sizes=(64, 64, 64), # ATIS=>64,SNIPS=>16\n",
    "    device=device,\n",
    "    shuffle=True,\n",
    "    sort_key= lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    "    repeat=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(869, 869, 120, 21, 4478)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab), len(TEXT.vocab.stoi), len(SLOT_LABEL.vocab.stoi), len(INTENT_LABEL.vocab.stoi), len(train_iter.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '<pad>',\n",
       " 0,\n",
       " ['O',\n",
       "  'B-toloc.city_name',\n",
       "  'B-fromloc.city_name',\n",
       "  'I-toloc.city_name',\n",
       "  'B-depart_date.day_name',\n",
       "  'B-airline_name',\n",
       "  'I-fromloc.city_name',\n",
       "  'B-depart_time.period_of_day',\n",
       "  'I-airline_name',\n",
       "  'B-depart_date.day_number',\n",
       "  'B-depart_date.month_name',\n",
       "  'B-depart_time.time',\n",
       "  'B-round_trip',\n",
       "  'I-round_trip',\n",
       "  'B-cost_relative',\n",
       "  'B-flight_mod',\n",
       "  'B-depart_time.time_relative',\n",
       "  'I-depart_time.time',\n",
       "  'B-stoploc.city_name',\n",
       "  'B-city_name',\n",
       "  'B-class_type',\n",
       "  'B-arrive_time.time',\n",
       "  'B-arrive_time.time_relative',\n",
       "  'I-class_type',\n",
       "  'I-arrive_time.time',\n",
       "  'B-flight_stop',\n",
       "  'B-airline_code',\n",
       "  'I-depart_date.day_number',\n",
       "  'I-fromloc.airport_name',\n",
       "  'B-arrive_date.day_name',\n",
       "  'B-flight_number',\n",
       "  'B-depart_date.date_relative',\n",
       "  'B-toloc.state_code',\n",
       "  'B-depart_date.today_relative',\n",
       "  'B-fromloc.airport_name',\n",
       "  'B-toloc.state_name',\n",
       "  'B-fare_basis_code',\n",
       "  'B-flight_time',\n",
       "  'B-or',\n",
       "  'B-arrive_time.period_of_day',\n",
       "  'I-airport_name',\n",
       "  'B-meal_description',\n",
       "  'I-cost_relative',\n",
       "  'B-fare_amount',\n",
       "  'I-toloc.airport_name',\n",
       "  'I-city_name',\n",
       "  'I-fare_amount',\n",
       "  'B-arrive_date.day_number',\n",
       "  'B-arrive_date.month_name',\n",
       "  'B-meal',\n",
       "  'B-fromloc.state_code',\n",
       "  'I-stoploc.city_name',\n",
       "  'B-transport_type',\n",
       "  'B-flight_days',\n",
       "  'B-connect',\n",
       "  'B-depart_time.period_mod',\n",
       "  'B-fromloc.state_name',\n",
       "  'B-toloc.airport_name',\n",
       "  'B-airport_name',\n",
       "  'B-economy',\n",
       "  'B-aircraft_code',\n",
       "  'B-mod',\n",
       "  'I-flight_time',\n",
       "  'B-airport_code',\n",
       "  'B-depart_time.end_time',\n",
       "  'B-depart_time.start_time',\n",
       "  'B-depart_date.year',\n",
       "  'B-restriction_code',\n",
       "  'I-transport_type',\n",
       "  'B-arrive_time.start_time',\n",
       "  'B-arrive_time.end_time',\n",
       "  'I-depart_time.end_time',\n",
       "  'B-toloc.airport_code',\n",
       "  'I-arrive_time.end_time',\n",
       "  'I-flight_stop',\n",
       "  'B-fromloc.airport_code',\n",
       "  'I-restriction_code',\n",
       "  'I-depart_date.today_relative',\n",
       "  'I-depart_time.start_time',\n",
       "  'I-toloc.state_name',\n",
       "  'I-economy',\n",
       "  'B-arrive_date.date_relative',\n",
       "  'I-flight_mod',\n",
       "  'I-arrive_time.start_time',\n",
       "  'I-fromloc.state_name',\n",
       "  'B-return_date.date_relative',\n",
       "  'B-state_code',\n",
       "  'B-meal_code',\n",
       "  'I-arrive_date.day_number',\n",
       "  'B-stoploc.state_code',\n",
       "  'I-depart_time.period_of_day',\n",
       "  'I-meal_code',\n",
       "  'B-arrive_time.period_mod',\n",
       "  'B-day_name',\n",
       "  'B-period_of_day',\n",
       "  'B-toloc.country_name',\n",
       "  'I-arrive_time.period_of_day',\n",
       "  'I-today_relative',\n",
       "  'B-day_number',\n",
       "  'B-days_code',\n",
       "  'B-month_name',\n",
       "  'B-return_date.day_number',\n",
       "  'B-return_date.month_name',\n",
       "  'B-return_time.period_mod',\n",
       "  'B-return_time.period_of_day',\n",
       "  'B-time',\n",
       "  'B-today_relative',\n",
       "  'I-arrive_time.time_relative',\n",
       "  'I-depart_time.time_relative',\n",
       "  'I-return_date.date_relative',\n",
       "  'I-return_date.today_relative',\n",
       "  'B-arrive_date.today_relative',\n",
       "  'B-return_date.day_name',\n",
       "  'B-return_date.today_relative',\n",
       "  'B-state_name',\n",
       "  'B-stoploc.airport_name',\n",
       "  'B-time_relative',\n",
       "  'I-fare_basis_code',\n",
       "  'I-meal_description',\n",
       "  'I-time'],\n",
       " Counter({'O': 32066,\n",
       "          'B-fromloc.city_name': 3892,\n",
       "          'B-toloc.city_name': 3919,\n",
       "          'B-round_trip': 323,\n",
       "          'I-round_trip': 314,\n",
       "          'B-cost_relative': 311,\n",
       "          'B-fare_amount': 46,\n",
       "          'I-fare_amount': 45,\n",
       "          'B-arrive_date.month_name': 43,\n",
       "          'B-arrive_date.day_number': 43,\n",
       "          'I-fromloc.city_name': 632,\n",
       "          'B-stoploc.city_name': 218,\n",
       "          'B-arrive_time.time_relative': 173,\n",
       "          'B-arrive_time.time': 191,\n",
       "          'I-arrive_time.time': 149,\n",
       "          'B-toloc.state_code': 76,\n",
       "          'I-toloc.city_name': 987,\n",
       "          'I-stoploc.city_name': 41,\n",
       "          'B-meal_description': 49,\n",
       "          'B-depart_date.month_name': 339,\n",
       "          'B-depart_date.day_number': 355,\n",
       "          'B-airline_name': 639,\n",
       "          'I-airline_name': 379,\n",
       "          'B-depart_time.period_of_day': 521,\n",
       "          'B-depart_date.day_name': 785,\n",
       "          'B-toloc.state_name': 70,\n",
       "          'B-depart_time.time_relative': 283,\n",
       "          'B-depart_time.time': 327,\n",
       "          'B-toloc.airport_name': 35,\n",
       "          'I-toloc.airport_name': 46,\n",
       "          'B-depart_date.date_relative': 76,\n",
       "          'B-or': 59,\n",
       "          'B-airline_code': 127,\n",
       "          'B-class_type': 194,\n",
       "          'I-class_type': 164,\n",
       "          'I-cost_relative': 49,\n",
       "          'I-depart_time.time': 264,\n",
       "          'B-fromloc.airport_name': 73,\n",
       "          'I-fromloc.airport_name': 97,\n",
       "          'B-city_name': 204,\n",
       "          'B-flight_mod': 289,\n",
       "          'B-meal': 43,\n",
       "          'B-economy': 34,\n",
       "          'B-fare_basis_code': 63,\n",
       "          'I-depart_date.day_number': 107,\n",
       "          'B-depart_date.today_relative': 75,\n",
       "          'B-flight_stop': 143,\n",
       "          'B-airport_code': 25,\n",
       "          'B-fromloc.state_name': 35,\n",
       "          'I-fromloc.state_name': 8,\n",
       "          'I-city_name': 45,\n",
       "          'B-connect': 36,\n",
       "          'B-arrive_date.day_name': 78,\n",
       "          'B-fromloc.state_code': 41,\n",
       "          'B-arrive_date.today_relative': 1,\n",
       "          'B-depart_date.year': 21,\n",
       "          'B-depart_time.start_time': 24,\n",
       "          'I-depart_time.start_time': 12,\n",
       "          'B-depart_time.end_time': 24,\n",
       "          'I-depart_time.end_time': 17,\n",
       "          'B-arrive_time.start_time': 18,\n",
       "          'B-arrive_time.end_time': 17,\n",
       "          'I-arrive_time.end_time': 16,\n",
       "          'I-flight_mod': 9,\n",
       "          'B-flight_days': 37,\n",
       "          'B-mod': 29,\n",
       "          'B-flight_number': 78,\n",
       "          'I-toloc.state_name': 12,\n",
       "          'B-meal_code': 6,\n",
       "          'I-meal_code': 4,\n",
       "          'B-airport_name': 34,\n",
       "          'I-airport_name': 50,\n",
       "          'I-flight_stop': 15,\n",
       "          'B-transport_type': 40,\n",
       "          'I-transport_type': 21,\n",
       "          'B-state_code': 7,\n",
       "          'B-aircraft_code': 30,\n",
       "          'B-toloc.country_name': 3,\n",
       "          'I-arrive_date.day_number': 6,\n",
       "          'B-toloc.airport_code': 16,\n",
       "          'B-return_date.date_relative': 7,\n",
       "          'I-return_date.date_relative': 2,\n",
       "          'B-flight_time': 59,\n",
       "          'I-economy': 10,\n",
       "          'B-fromloc.airport_code': 14,\n",
       "          'B-arrive_time.period_of_day': 51,\n",
       "          'B-depart_time.period_mod': 35,\n",
       "          'I-flight_time': 26,\n",
       "          'B-return_date.day_name': 1,\n",
       "          'B-arrive_date.date_relative': 9,\n",
       "          'B-restriction_code': 21,\n",
       "          'I-restriction_code': 13,\n",
       "          'B-arrive_time.period_mod': 3,\n",
       "          'I-arrive_time.period_of_day': 3,\n",
       "          'B-period_of_day': 3,\n",
       "          'B-stoploc.state_code': 5,\n",
       "          'I-depart_date.today_relative': 12,\n",
       "          'I-fare_basis_code': 1,\n",
       "          'I-arrive_time.start_time': 8,\n",
       "          'B-time': 2,\n",
       "          'B-today_relative': 2,\n",
       "          'I-today_relative': 3,\n",
       "          'B-state_name': 1,\n",
       "          'B-days_code': 2,\n",
       "          'I-depart_time.period_of_day': 5,\n",
       "          'I-arrive_time.time_relative': 2,\n",
       "          'B-time_relative': 1,\n",
       "          'I-time': 1,\n",
       "          'B-return_date.month_name': 2,\n",
       "          'B-return_date.day_number': 2,\n",
       "          'I-depart_time.time_relative': 2,\n",
       "          'B-stoploc.airport_name': 1,\n",
       "          'B-day_name': 3,\n",
       "          'B-month_name': 2,\n",
       "          'B-day_number': 2,\n",
       "          'B-return_time.period_mod': 2,\n",
       "          'B-return_time.period_of_day': 2,\n",
       "          'B-return_date.today_relative': 1,\n",
       "          'I-return_date.today_relative': 2,\n",
       "          'I-meal_description': 1}))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['<tag>'], TEXT.vocab.itos[1], SLOT_LABEL.vocab.stoi['O'], SLOT_LABEL.vocab.itos, SLOT_LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(24, 14))\n",
    "sns.barplot(x=list(SLOT_LABEL.vocab.freqs.keys()), y=list(SLOT_LABEL.vocab.freqs.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = SLOT_LABEL.vocab\n",
    "# freqs_dict = dict(SLOT_LABEL.vocab.freqs)\n",
    "# slot_distribute = []\n",
    "# for k in vocab.itos:\n",
    "#     slot_distribute.append(freqs_dict[k])\n",
    "# slot_distribute = torch.tensor(slot_distribute, dtype=torch.float32)\n",
    "# print(slot_distribute)\n",
    "# print(F.softmax(slot_distribute, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['list', 'list', 'baltimore', 'las', 'las', 'ground', 'ground', 'what', 'list', 'flights', 'flights', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'show', 'what', 'does', 'which', 'what', 'what', 'what', 'list', 'list', 'list', 'what', 'what', 'what', 'what', 'what', 'what', 'st.', 'what', 'which', 'which', 'which', 'which', 'what', 'what', 'which', 'what', 'list', 'what', 'what', 'what', 'what', 'what', 'what', 'what', 'minneapolis', 'what', 'what', 'what', 'list', 'list', 'what', 'what', 'list', 'list', 'list', 'list']\n",
      "tensor(5, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(test_iter):\n",
    "    print([TEXT.vocab.itos[i] for i in batch.text[0][:, 0]])\n",
    "    print(batch.text[1][0])\n",
    "#     print([(TEXT_EDGE.vocab.itos[i]).split() for i in batch.edge[0][0]])\n",
    "#     print(batch.edge[1][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copy file (including metric) from MiuLab:\n",
    "\n",
    "    https://github.com/MiuLab/SlotGated-SLU\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# compute f1 score is modified from conlleval.pl\n",
    "def __startOfChunk(prevTag, tag, prevTagType, tagType, chunkStart=False):\n",
    "    if prevTag == 'B' and tag == 'B':\n",
    "        chunkStart = True\n",
    "    if prevTag == 'I' and tag == 'B':\n",
    "        chunkStart = True\n",
    "    if prevTag == 'O' and tag == 'B':\n",
    "        chunkStart = True\n",
    "    if prevTag == 'O' and tag == 'I':\n",
    "        chunkStart = True\n",
    "\n",
    "    if prevTag == 'E' and tag == 'E':\n",
    "        chunkStart = True\n",
    "    if prevTag == 'E' and tag == 'I':\n",
    "        chunkStart = True\n",
    "    if prevTag == 'O' and tag == 'E':\n",
    "        chunkStart = True\n",
    "    if prevTag == 'O' and tag == 'I':\n",
    "        chunkStart = True\n",
    "\n",
    "    if tag != 'O' and tag != '.' and prevTagType != tagType:\n",
    "        chunkStart = True\n",
    "    return chunkStart\n",
    "\n",
    "\n",
    "def __endOfChunk(prevTag, tag, prevTagType, tagType, chunkEnd=False):\n",
    "    if prevTag == 'B' and tag == 'B':\n",
    "        chunkEnd = True\n",
    "    if prevTag == 'B' and tag == 'O':\n",
    "        chunkEnd = True\n",
    "    if prevTag == 'I' and tag == 'B':\n",
    "        chunkEnd = True\n",
    "    if prevTag == 'I' and tag == 'O':\n",
    "        chunkEnd = True\n",
    "\n",
    "    if prevTag == 'E' and tag == 'E':\n",
    "        chunkEnd = True\n",
    "    if prevTag == 'E' and tag == 'I':\n",
    "        chunkEnd = True\n",
    "    if prevTag == 'E' and tag == 'O':\n",
    "        chunkEnd = True\n",
    "    if prevTag == 'I' and tag == 'O':\n",
    "        chunkEnd = True\n",
    "\n",
    "    if prevTag != 'O' and prevTag != '.' and prevTagType != tagType:\n",
    "        chunkEnd = True\n",
    "    return chunkEnd\n",
    "\n",
    "\n",
    "def __splitTagType(tag):\n",
    "    s = tag.split('-')\n",
    "    if len(s) > 2 or len(s) == 0:\n",
    "        raise ValueError('tag format wrong. it must be B-xxx.xxx')\n",
    "    if len(s) == 1:\n",
    "        tag = s[0]\n",
    "        tagType = \"\"\n",
    "    else:\n",
    "        tag = s[0]\n",
    "        tagType = s[1]\n",
    "    return tag, tagType\n",
    "\n",
    "\n",
    "def computeF1Score(correct_slots, pred_slots):\n",
    "    correctChunk = {}\n",
    "    correctChunkCnt = 0.0\n",
    "    foundCorrect = {}\n",
    "    foundCorrectCnt = 0.0\n",
    "    foundPred = {}\n",
    "    foundPredCnt = 0.0\n",
    "    correctTags = 0.0\n",
    "    tokenCount = 0.0\n",
    "    for correct_slot, pred_slot in zip(correct_slots, pred_slots):\n",
    "        inCorrect = False\n",
    "        lastCorrectTag = 'O'\n",
    "        lastCorrectType = ''\n",
    "        lastPredTag = 'O'\n",
    "        lastPredType = ''\n",
    "        for c, p in zip(correct_slot, pred_slot):\n",
    "            correctTag, correctType = __splitTagType(c)\n",
    "            predTag, predType = __splitTagType(p)\n",
    "\n",
    "            if inCorrect == True:\n",
    "                if __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n",
    "                    __endOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n",
    "                    (lastCorrectType == lastPredType):\n",
    "                    inCorrect = False\n",
    "                    correctChunkCnt += 1.0\n",
    "                    if lastCorrectType in correctChunk:\n",
    "                        correctChunk[lastCorrectType] += 1.0\n",
    "                    else:\n",
    "                        correctChunk[lastCorrectType] = 1.0\n",
    "                elif __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) != \\\n",
    "                    __endOfChunk(lastPredTag, predTag, lastPredType, predType) or \\\n",
    "                    (correctType != predType):\n",
    "                    inCorrect = False\n",
    "\n",
    "            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n",
    "                __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n",
    "                (correctType == predType):\n",
    "                inCorrect = True\n",
    "\n",
    "            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True:\n",
    "                foundCorrectCnt += 1\n",
    "                if correctType in foundCorrect:\n",
    "                    foundCorrect[correctType] += 1.0\n",
    "                else:\n",
    "                    foundCorrect[correctType] = 1.0\n",
    "\n",
    "            if __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True:\n",
    "                foundPredCnt += 1.0\n",
    "                if predType in foundPred:\n",
    "                    foundPred[predType] += 1.0\n",
    "                else:\n",
    "                    foundPred[predType] = 1.0\n",
    "\n",
    "            if correctTag == predTag and correctType == predType:\n",
    "                correctTags += 1.0\n",
    "\n",
    "            tokenCount += 1.0\n",
    "\n",
    "            lastCorrectTag = correctTag\n",
    "            lastCorrectType = correctType\n",
    "            lastPredTag = predTag\n",
    "            lastPredType = predType\n",
    "\n",
    "        if inCorrect == True:\n",
    "            correctChunkCnt += 1.0\n",
    "            if lastCorrectType in correctChunk:\n",
    "                correctChunk[lastCorrectType] += 1.0\n",
    "            else:\n",
    "                correctChunk[lastCorrectType] = 1.0\n",
    "\n",
    "    if foundPredCnt > 0:\n",
    "        precision = 1.0 * correctChunkCnt / foundPredCnt\n",
    "    else:\n",
    "        precision = 0\n",
    "\n",
    "    if foundCorrectCnt > 0:\n",
    "        recall = 1.0 * correctChunkCnt / foundCorrectCnt\n",
    "    else:\n",
    "        recall = 0\n",
    "\n",
    "    if (precision + recall) > 0:\n",
    "        f1 = (2.0 * precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "\n",
    "    return f1, precision, recall\n",
    "\n",
    "pred_slot = [['O', 'O', 'B-airport_code', 'I-airport_code'], ['O', 'O', 'B-airport_code', 'I-airport_code']]\n",
    "real_slot = [['O', 'O', 'B-airport_code', 'I-airport_code'], ['O', 'O', 'B-airport_code', 'I-airport_code']]\n",
    "slot_f1_socre = computeF1Score(pred_slot, real_slot)[0]\n",
    "print(slot_f1_socre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn_msg = fn.u_mul_e('h', 'w', 'm')\n",
    "# gnn_reduce = fn.max('m', 'h')\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "        self.gru = nn.GRUCell(out_feats, out_feats)\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        old_h = node.data['h']\n",
    "        h = F.relu(self.gru(h, old_h))\n",
    "        return {'h': h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation=None):\n",
    "        super(GCN, self).__init__()\n",
    "        self.node_apply_module = NodeApplyModule(in_feats, out_feats, activation)\n",
    "    def forward(self, g, feature):\n",
    "        if feature is not None:\n",
    "            g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(self.node_apply_module)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_msg = fn.copy_u(u='z', out='m')\n",
    "# # def udf_u_e(edges):\n",
    "# #     print(edges.src['z'].shape)\n",
    "# #     return {'m' : edges.src['z']}\n",
    "# # test_reduce = fn.sum(msg='m', out='h')\n",
    "\n",
    "# class MyGATLayer(nn.Module):\n",
    "#     def __init__(self, in_dim, out_dim, dropout):\n",
    "#         super(MyGATLayer, self).__init__()\n",
    "#         # equation (1)\n",
    "#         self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "#         # equation (2)\n",
    "#         self.attn_fc_l = nn.Linear(in_dim, 1, bias=False)\n",
    "#         self.attn_fc_r = nn.Linear(in_dim, 1, bias=False)\n",
    "#         self.gru = nn.GRUCell(out_dim, out_dim)\n",
    "# #         self.dropout = nn.Dropout(p=dropout)\n",
    "#         self.reset_parameters()\n",
    "    \n",
    "#     def myinitializer(shape, dtype, ctx, id_range):\n",
    "#         return torch.zeros(shape, dtype=dtype, device=ctx)\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "#         gain = nn.init.calculate_gain('relu')\n",
    "#         nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "#         nn.init.xavier_normal_(self.attn_fc_l.weight, gain=gain)\n",
    "#         nn.init.xavier_normal_(self.attn_fc_r.weight, gain=gain)\n",
    "\n",
    "# #     def reduce_func(self, nodes):\n",
    "# #         # reduce UDF for equation (3) & (4)\n",
    "# #         # equation (3)\n",
    "# #         alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "# #         # equation (4)\n",
    "# #         h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        \n",
    "# #         old_h = nodes.data['h']\n",
    "# # #         h = F.relu(self.gru(h, old_h))\n",
    "# # #         h = old_h + F.relu(self.gru(h, old_h))\n",
    "# # #         h = old_h + self.dropout(F.relu(self.gru(h, old_h)))\n",
    "\n",
    "# # #         print('h', h)\n",
    "# #         return {'h': h}\n",
    "\n",
    "#     def forward(self, g, h):\n",
    "#         # equation (1)\n",
    "#         feat_src = feat_dst = self.fc(h)\n",
    "# #         g.ndata['z'] = z\n",
    "        \n",
    "#         el = self.attn_fc_l(feat_src)\n",
    "#         er = self.attn_fc_r(feat_dst)\n",
    "        \n",
    "#         g.srcdata.update({'ft': feat_src, 'el': el})\n",
    "#         g.dstdata.update({'er': er})\n",
    "        \n",
    "#         g.set_n_initializer(self.myinitializer)\n",
    "#         g.set_e_initializer(self.myinitializer)\n",
    "        \n",
    "#         # compute edge attention, el and er are a_l Wh_i and a_r Wh_j respectively.\n",
    "#         g.apply_edges(fn.u_add_v('el', 'er', 'e'))\n",
    "#         a = F.leaky_relu(g.edata.pop('e'))\n",
    "        \n",
    "#         # compute softmax\n",
    "#         g.edata['a'] = edge_softmax(g, a)\n",
    "\n",
    "#         # message passing\n",
    "#         g.update_all(fn.u_mul_e('ft', 'a', 'm'), fn.sum('m', 'h'))\n",
    "# #         g.update_all(fn.copy_u('ft' ,'m'), fn.sum('m', 'h'))\n",
    "# #         g.update_all(fn.u_add_v('ft', 'ft', 'm'), fn.max('m', 'h'))\n",
    "    \n",
    "\n",
    "#         h = g.ndata.pop('h')\n",
    "#         h = F.relu(self.gru(h, feat_dst))\n",
    "# # #         h = old_h + F.relu(self.gru(h, old_h))\n",
    "# # #         h = old_h + self.dropout(F.relu(self.gru(h, old_h)))\n",
    "        \n",
    "#         return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_msg = fn.copy_u(u='z', out='m')\n",
    "# def udf_u_e(edges):\n",
    "# #     print(edges.src['z'].shape)\n",
    "#     return {'m' : edges.src['z']}\n",
    "# test_reduce = fn.sum(msg='m', out='h')\n",
    "\n",
    "# def myinitializer(shape, dtype, ctx, id_range):\n",
    "#     return torch.zeros(shape, dtype=dtype, device=ctx)\n",
    "\n",
    "class MyGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout):\n",
    "        super(MyGATLayer, self).__init__()\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "        self.gru = nn.GRUCell(out_dim, out_dim)\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "#     def myinitializer(shape, dtype, ctx, id_range):\n",
    "#         return torch.zeros(shape, dtype=dtype, device=ctx)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        \n",
    "        old_h = nodes.data['h']\n",
    "        h = F.relu(self.gru(h, old_h))\n",
    "#         h = old_h + F.relu(self.gru(h, old_h))\n",
    "#         h = self.dropout(F.relu(self.gru(h, old_h)))\n",
    "\n",
    "#         print('h', h)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)        \n",
    "        g.ndata['z'] = z\n",
    "        \n",
    "        g.set_n_initializer(dgl.init.zero_initializer)\n",
    "        g.set_e_initializer(dgl.init.zero_initializer)\n",
    "        \n",
    "        # equation (2)\n",
    "        g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "#         g.update_all(udf_u_e, test_reduce)\n",
    "#         g.update_all(test_msg, test_reduce)\n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "etypes = torch.tensor([1,0,0,0,1,1,1,0])\n",
    "eids = (etypes == 0).nonzero().view(-1)\n",
    "print(eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends a message of node feature h.\n",
    "msg = fn.copy_e(e='W_e*h', out='m')\n",
    "\n",
    "def reduce(nodes):\n",
    "    \"\"\"Take an average over all neighbor node features hu and use it to\n",
    "    overwrite the original node feature.\"\"\"\n",
    "    accum = torch.sum(nodes.mailbox['m'], 1)\n",
    "    return {'h': accum}\n",
    "\n",
    "class ReduceApplyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_feats, out_feats, dropout):\n",
    "        super(ReduceApplyModule, self).__init__()\n",
    "        self.gru = nn.GRUCell(in_feats, out_feats)\n",
    "        self.lstm = nn.LSTMCell(in_feats, out_feats)\n",
    "        self.norm = nn.LayerNorm(out_feats)\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.gru.reset_parameters()\n",
    "#         self.lstm.reset_parameters()\n",
    "    \n",
    "    def forward(self, nodes):\n",
    "        \"\"\"Take an average over all neighbor node features hu and use it to\n",
    "        overwrite the original node feature.\"\"\"\n",
    "#         print(nodes.mailbox['m'].size())\n",
    "        accum = torch.max(nodes.mailbox['m'], 1)[0]\n",
    "#         accum = torch.sum(nodes.mailbox['m'], 1)\n",
    "#         print(nodes.data['h'].size(), accum.size())\n",
    "        old_h = nodes.data['h']\n",
    "#         lstm = self.lstm(accum, (old_h, old_h))[0]\n",
    "        h = old_h + self.dropout(F.relu(self.gru(accum, old_h)))\n",
    "#         h = old_h + F.dropout(F.relu(self.lstm(accum, (old_h, old_h))[0]), p=dropout)\n",
    "#         h = F.dropout(F.relu(self.gru(accum, old_h)), p=dropout)\n",
    "#         h = old_h + F.dropout(F.relu(self.linear(accum)))\n",
    "\n",
    "#         h = F.dropout(F.relu(lstm), p=dropout)\n",
    "#         h = self.norm(h)\n",
    "        return {'h': h}\n",
    "\n",
    "class EdgeApplyModule(nn.Module):\n",
    "    \"\"\"Update the node feature hv with ReLU(Whv+b).\"\"\"\n",
    "    def __init__(self, in_feats, out_feats, dropout):\n",
    "        super(EdgeApplyModule, self).__init__()\n",
    "        self.linear_intent = nn.Linear(in_feats, out_feats)\n",
    "        self.linear_slot = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, edges):\n",
    "        print(edges.data['etype'])\n",
    "        if edges.data['etype'] == 1:\n",
    "            h = self.linear_slot(edges.src['h'])\n",
    "        else:\n",
    "            h = self.linear_intent(edges.src['h'])\n",
    "        h = torch.tanh(h)\n",
    "#         h = F.dropout(F.relu(h))\n",
    "        return {'W_e*h' : h}\n",
    "\n",
    "class MyGraph(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, n_etypes, dropout):\n",
    "        super(MyGraph, self).__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "#         self.edge_apply_module = EdgeApplyModule(in_feats, out_feats, dropout)\n",
    "        self.reduce_apply_module = ReduceApplyModule(in_feats, out_feats, dropout)\n",
    "        self._n_etypes = n_etypes\n",
    "        self.linears = nn.ModuleList(\n",
    "            [nn.Linear(out_feats, out_feats) for _ in range(n_etypes)]\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = init.calculate_gain('relu')\n",
    "        for linear in self.linears:\n",
    "            init.xavier_normal_(linear.weight, gain=gain)\n",
    "            init.zeros_(linear.bias)\n",
    "        \n",
    "    def forward(self, g, feats, etypes):\n",
    "        g.ndata['h'] = feats\n",
    "        for i in range(self._n_etypes):\n",
    "            eids = (etypes == i).nonzero().view(-1)\n",
    "            g.apply_edges(\n",
    "                lambda edges: {'W_e*h': torch.tanh(self.linears[i](edges.src['h']))},\n",
    "                eids\n",
    "            )\n",
    "        g.update_all(msg, self.reduce_apply_module)\n",
    "#         g.update_all(msg, reduce)\n",
    "#         max_nodes = dgl.max_nodes(g, feat='h')\n",
    "        feats = g.ndata.pop('h')\n",
    "        return feats\n",
    "\n",
    "#     def forward(self, g, feats):\n",
    "#         g.ndata['h'] = feats\n",
    "#         g.apply_edges(\n",
    "#             lambda edges: {'W_e*h': self.linears[0](edges.src['h'])}\n",
    "#         )\n",
    "#         g.update_all(msg, self.reduce_apply_module)\n",
    "# #         g.update_all(msg, reduce)\n",
    "# #         max_nodes = dgl.max_nodes(g, feat='h')\n",
    "#         feats = g.ndata.pop('h')\n",
    "#         return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 6]),\n",
       " array([0, 0, 1, 2]),\n",
       " array([1, 1, 2, 6]),\n",
       " array([0]),\n",
       " (1, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])\n",
    "\n",
    "le.classes_, le.transform([1, 1, 2, 6]), le.inverse_transform([0, 0, 1, 2]), le.transform([1]), tuple([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "alist = [1, 2, 1, 6]\n",
    "blist = [1, 2, 6]\n",
    "[alist.index(b) for b in blist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([4, 5, 6, 1, 2, 3]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "tensor([[4, 5, 6],\n",
      "        [1, 2, 0],\n",
      "        [3, 0, 0]])\n",
      "tensor([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "seq = torch.tensor([[4,5,6], [1,2,0], [3,0,0]])\n",
    "lens = [3, 2, 1]\n",
    "packed = pack_padded_sequence(seq, lens, batch_first=False)\n",
    "print(packed)\n",
    "# PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]),\n",
    "#                sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n",
    "seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=False)\n",
    "print(seq_unpacked)\n",
    "# tensor([[1, 2, 0],\n",
    "#         [3, 0, 0],\n",
    "#         [4, 5, 6]])\n",
    "print(lens_unpacked)\n",
    "# tensor([2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dglgraph(text, text_include_length, text_edge, text_edge_include_length, text_embedding, edge_embedding):\n",
    "    sub_graphs = []\n",
    "    for i in range(len(text)):\n",
    "        sub_graph = dgl.DGLGraph()\n",
    "        # preprocessing nodes\n",
    "        doc = text[i][:text_include_length[i]]\n",
    "        doc_encoder = LabelEncoder()\n",
    "        doc_encoder.fit_transform(doc.cpu().numpy())\n",
    "        \n",
    "        node_index_select = [doc.cpu().numpy().tolist().index(item) for item in doc_encoder.classes_]\n",
    "        \n",
    "        sub_graph.add_nodes(len(doc_encoder.classes_), {'h': torch.index_select(text_embedding[i], 0, torch.tensor(node_index_select).to(device))})\n",
    "        # preprocessing edges\n",
    "        doc_edge = text_edge[i][:text_edge_include_length[i]]\n",
    "        \n",
    "        new_edge_list = []\n",
    "        edge_index_select = []\n",
    "        for j in range(len(doc_edge)):\n",
    "            edge_key_split = (TEXT_EDGE.vocab.itos[doc_edge[j]]).split()\n",
    "            if len(edge_key_split) == 2:\n",
    "                src = TEXT.vocab.stoi[edge_key_split[0]]\n",
    "                dst = TEXT.vocab.stoi[edge_key_split[1]]\n",
    "                new_edge_list.append(tuple(doc_encoder.transform([src, dst])))\n",
    "                edge_index_select.append(j)\n",
    "        \n",
    "        new_src, new_dst = tuple(zip(*new_edge_list))\n",
    "        \n",
    "        sub_graph.add_edges(new_src, new_dst, {'w':torch.index_select(edge_embedding[i], 0, torch.tensor(edge_index_select).to(device))})\n",
    "        # summary\n",
    "        sub_graphs.append(sub_graph)\n",
    "    return sub_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dglgraph(x, x_length):\n",
    "    sub_graphs = []\n",
    "    for i in range(len(x)):\n",
    "        sub_graph = dgl.DGLGraph()\n",
    "        # preprocessing nodes\n",
    "        sub_graph.add_nodes(x_length[i], {'h':x[i][:x_length[i]]})\n",
    "        # preprocessing edges\n",
    "        src, dst = text_edge_tokenize(np.arange(x_length[i]))\n",
    "        sub_graph.add_edges(src, dst)\n",
    "        # summary\n",
    "        sub_graphs.append(sub_graph)\n",
    "    return sub_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dglgraph(x, x_length):\n",
    "    sub_graphs = []\n",
    "    for i in range(len(x)):\n",
    "        sub_graph = dgl.DGLGraph()\n",
    "        # preprocessing nodes\n",
    "        sub_graph.add_nodes(x_length[i], {'h':x[i][:x_length[i]]})\n",
    "        # preprocessing edges\n",
    "        sub_graph.add_edges(0, range(1, x_length[i]))\n",
    "        sub_graph.add_edges(range(1, x_length[i]), 0)\n",
    "        sub_graph.add_edges(range(1, x_length[i]), list(range(2, x_length[i]))+[1])\n",
    "        sub_graph.add_edges(list(range(2, x_length[i]))+[1], range(1, x_length[i]))\n",
    "#         sub_graph.add_edges(range(x_length[i]), range(x_length[i]))\n",
    "        \n",
    "        # summary\n",
    "        sub_graphs.append(sub_graph)\n",
    "    return sub_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dglgraph(x, x_intent, x_length):\n",
    "    sub_graphs = []\n",
    "    for i in range(len(x)):\n",
    "        sub_graph = dgl.DGLGraph()\n",
    "        # preprocessing nodes\n",
    "        sub_graph.add_nodes(1, {'h': x_intent[i].unsqueeze(0)})\n",
    "        sub_graph.add_nodes(x_length[i], {'h':x[i][:x_length[i]]})\n",
    "        # preprocessing edges\n",
    "#         sub_graph.add_edges(0, range(1, x_length[i]+1), {'etype': torch.zeros(x_length[i])})\n",
    "#         sub_graph.add_edges(range(1, x_length[i]+1), 0, {'etype': torch.zeros(x_length[i])})\n",
    "#         sub_graph.add_edges(range(1, x_length[i]+1), list(range(2, x_length[i]+1))+[1], {'etype': torch.ones(x_length[i])})\n",
    "#         sub_graph.add_edges(list(range(2, x_length[i]+1))+[1], range(1, x_length[i]+1), {'etype': torch.ones(x_length[i])})\n",
    "#         sub_graph.add_edges(range(x_length[i]+1), range(x_length[i]+1), {'etype': torch.ones(x_length[i]+1)+1})\n",
    "\n",
    "        sub_graph.add_edges(0, range(1, x_length[i]+1))\n",
    "        sub_graph.add_edges(range(1, x_length[i]+1), 0)\n",
    "        sub_graph.add_edges(range(1, x_length[i]+1), list(range(2, x_length[i]+1))+[1])\n",
    "        sub_graph.add_edges(list(range(2, x_length[i]+1))+[1], range(1, x_length[i]+1))\n",
    "#         sub_graph.add_edges(range(1, x_length[i]), list(range(2, x_length[i]+1)))\n",
    "#         sub_graph.add_edges(list(range(2, x_length[i]+1)), range(1, x_length[i]))\n",
    "        \n",
    "        sub_graph.add_edges(range(x_length[i]+1), range(x_length[i]+1))\n",
    "        \n",
    "        # summary\n",
    "        sub_graphs.append(sub_graph)\n",
    "    return sub_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 2])\n",
      "{'h': tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [2, 2],\n",
      "        [3, 3],\n",
      "        [4, 4],\n",
      "        [5, 5]])}\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "x = torch.tensor([\n",
    "    [[1, 1],[2, 2],[3, 3],[4, 4],[5, 5]],\n",
    "    [[5, 5],[6, 6],[7, 7],[1, 1],[0, 0]],\n",
    "    [[7, 8],[9, 4],[10, 4],[0, 0],[0, 0]],\n",
    "    [[8, 8],[9, 9],[0, 0],[0, 0],[0, 0]]\n",
    "])\n",
    "x_intent = torch.tensor([\n",
    "    [1,1],[2,2],[3,3],[4,4]\n",
    "])\n",
    "print(x.size())\n",
    "x_length = torch.tensor([5, 4, 3, 2])\n",
    "# sub_graphs = generate_dglgraph(x, x_length)\n",
    "sub_graphs = generate_dglgraph(x, x_intent, x_length)\n",
    "g = sub_graphs[0]\n",
    "print(g.ndata)\n",
    "print(g.edata)\n",
    "nx.draw(g.to_networkx(), with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(1, 7)) + [1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 2]) torch.Size([3])\n",
      "(tensor([[[1, 1],\n",
      "         [2, 2],\n",
      "         [3, 3],\n",
      "         [4, 4]],\n",
      "\n",
      "        [[5, 5],\n",
      "         [6, 6],\n",
      "         [7, 7],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[8, 8],\n",
      "         [9, 9],\n",
      "         [0, 0],\n",
      "         [0, 0]]]), tensor([3, 3, 2, 1])) torch.Size([3, 4, 2])\n",
      "tensor([[1, 1],\n",
      "        [5, 5],\n",
      "        [8, 8]])\n",
      "tensor([[[2, 2],\n",
      "         [3, 3],\n",
      "         [4, 4]],\n",
      "\n",
      "        [[6, 6],\n",
      "         [7, 7],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[9, 9],\n",
      "         [0, 0],\n",
      "         [0, 0]]])\n",
      "tensor([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1, 1],[2, 2],[3, 3],[4, 4],\n",
    "    [5, 5],[6, 6],[7, 7],\n",
    "    [8, 8],[9, 9]\n",
    "])\n",
    "x_length = torch.tensor([4, 3, 2])\n",
    "print(x.size(), x_length.size())\n",
    "packed_sequence = nn.utils.rnn.PackedSequence(data=x, batch_sizes=x_length)\n",
    "x = nn.utils.rnn.pad_packed_sequence(packed_sequence, batch_first=False)\n",
    "print(x, x[0].size())\n",
    "# print(x[0].transpose(0, 1))\n",
    "print(x[0][:,0])\n",
    "print(x[0][:,1:])\n",
    "print(x_length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[4., 4.],\n",
      "         [3., 3.]],\n",
      "\n",
      "        [[5., 7.],\n",
      "         [6., 4.]]])\n",
      "torch.Size([3, 2, 2])\n",
      "torch.return_types.max(\n",
      "values=tensor([[2., 2.],\n",
      "        [4., 4.],\n",
      "        [6., 7.]]),\n",
      "indices=tensor([[1, 1],\n",
      "        [0, 0],\n",
      "        [1, 0]]))\n",
      "tensor([[1.5000, 1.5000],\n",
      "        [3.5000, 3.5000],\n",
      "        [5.5000, 5.5000]])\n"
     ]
    }
   ],
   "source": [
    "m = torch.tensor([\n",
    "    [[1,1],[2,2]],\n",
    "    [[4,4],[3,3]],\n",
    "    [[5,7],[6,4]]\n",
    "], dtype=torch.float32)\n",
    "# m = m.transpose(0,1)\n",
    "print(m)\n",
    "print(m.size())\n",
    "out = torch.max(m, 1)\n",
    "print(out)\n",
    "out = torch.mean(m, 1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "tensor([[1, 1, 1, 4, 4, 4],\n",
      "        [2, 2, 2, 5, 5, 5],\n",
      "        [3, 3, 3, 6, 6, 6]])\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.tensor([\n",
    "    [[1,1,1],[2,2,2],[3,3,3]],\n",
    "    [[4,4,4],[5,5,5],[6,6,6]]\n",
    "])\n",
    "print(hidden.size())\n",
    "print(torch.cat(tuple([hidden[i] for i in range(hidden.size(0))]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False],\n",
       "        [False, False, False, False,  True,  True],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_key_padding_mask(include_length): # return (N,L)\n",
    "    max_length = torch.max(include_length)\n",
    "#     print([torch.arange(max_length)>=i for i in include_length])\n",
    "    mask = torch.stack([torch.arange(max_length)>=i for i in include_length])\n",
    "    return mask\n",
    "    \n",
    "include_length = torch.tensor([6, 4, 3, 2])\n",
    "generate_key_padding_mask(include_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False, False,  True,  True]],\n",
       "\n",
       "        [[False, False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True]],\n",
       "\n",
       "        [[False, False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True]]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_key_padding_mask(include_length): # return (N,L,L)\n",
    "    max_length = torch.max(include_length)\n",
    "#     print([torch.arange(max_length)>=i for i in include_length])\n",
    "    mask = torch.stack([torch.arange(max_length).to(device)>=i for i in include_length])\n",
    "    mask = mask.unsqueeze(1).expand(-1, mask.size(1), -1)\n",
    "    return mask\n",
    "    \n",
    "include_length = torch.tensor([6, 4, 3, 2]).to(device)\n",
    "generate_key_padding_mask(include_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False,  True],\n",
       "         [False, False, False, False, False, False]],\n",
       "\n",
       "        [[False,  True,  True,  True,  True,  True],\n",
       "         [False, False,  True,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False,  True],\n",
       "         [False, False, False, False, False, False]]], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(q):\n",
    "    r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "        Unmasked positions are filled with float(0.0).\n",
    "    \"\"\"\n",
    "    mask = (torch.triu(torch.ones(q.size(1), q.size(1)).to(device), 1) == 1)\n",
    "#     mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    mask = mask.unsqueeze(0).expand(q.size(0), -1, -1)  # [B, L, L]\n",
    "    return mask\n",
    "q = torch.tensor([\n",
    "    [[1,1,1],[2,2,2],[3,3,3], [1,1,1],[2,2,2],[3,3,3]],\n",
    "    [[4,4,4],[5,5,5],[6,6,6], [4,4,4],[5,5,5],[6,6,6]]\n",
    "]).to(device)\n",
    "generate_square_subsequent_mask(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, q, k, v, scale=None, attn_mask=None):\n",
    "        '''\n",
    "        前向传播\n",
    "\n",
    "        args:\n",
    "            q: Queries张量，形状[B, L_q, D_q]\n",
    "            k: keys张量， 形状[B, L_k, D_k]\n",
    "            v: Values张量，形状[B, L_v, D_v]\n",
    "            scale: 缩放因子，一个浮点标量\n",
    "            attn_mask: Masking张量，形状[B, L_q, L_k]\n",
    "        returns:\n",
    "            上下文张量和attention张量\n",
    "        '''\n",
    "        attn = torch.bmm(q, k.transpose(1,2))\n",
    "        if scale:\n",
    "            attn = attn * scale\n",
    "#         if attn_mask:\n",
    "            # 给需要mask的地方设置一个负无穷\n",
    "        attn = attn.masked_fill(attn_mask, -np.inf)\n",
    "        # 计算softmax\n",
    "        attn = self.softmax(attn)\n",
    "        # 添加dropout\n",
    "        attn = self.dropout(attn)\n",
    "        # 和v相乘\n",
    "        context = torch.bmm(attn, v)\n",
    "        \n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 支持多分类和二分类\n",
    "class FocalLoss(nn.Module):\n",
    "  \"\"\"\n",
    "  This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "  \"Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)\"\n",
    "    Focal_Loss= -1*alpha*(1-pt)^gamma*log(pt)\n",
    "  :param num_class:\n",
    "  :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "  :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "          focus on hard misclassified example\n",
    "  :param smooth: (float,double) smooth value when cross entropy\n",
    "  :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "  :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "  \"\"\"\n",
    " \n",
    "  def __init__(self, num_class, alpha=None, gamma=2, balance_index=-1, smooth=None, size_average=True):\n",
    "    super(FocalLoss, self).__init__()\n",
    "    self.num_class = num_class\n",
    "    self.alpha = alpha\n",
    "    self.gamma = gamma\n",
    "    self.smooth = smooth\n",
    "    self.size_average = size_average\n",
    " \n",
    "    if self.alpha is None:\n",
    "      self.alpha = torch.ones(self.num_class, 1)\n",
    "    elif isinstance(self.alpha, (list, np.ndarray)):\n",
    "      assert len(self.alpha) == self.num_class\n",
    "      self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n",
    "      self.alpha = self.alpha / self.alpha.sum()\n",
    "    elif isinstance(self.alpha, float):\n",
    "      alpha = torch.ones(self.num_class, 1)\n",
    "      alpha = alpha * (1 - self.alpha)\n",
    "      alpha[balance_index] = self.alpha\n",
    "      self.alpha = alpha\n",
    "    else:\n",
    "      raise TypeError(\"Not support alpha type\")\n",
    " \n",
    "    if self.smooth is not None:\n",
    "      if self.smooth < 0 or self.smooth > 1.0:\n",
    "        raise ValueError(\"smooth value should be in [0,1]\")\n",
    " \n",
    "  def forward(self, input, target):\n",
    "    logit = F.softmax(input, dim=1)\n",
    " \n",
    "    if logit.dim() > 2:\n",
    "      # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "      logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "      logit = logit.permute(0, 2, 1).contiguous()\n",
    "      logit = logit.view(-1, logit.size(-1))\n",
    "    target = target.view(-1, 1)\n",
    " \n",
    "    # N = input.size(0)\n",
    "    # alpha = torch.ones(N, self.num_class)\n",
    "    # alpha = alpha * (1 - self.alpha)\n",
    "    # alpha = alpha.scatter_(1, target.long(), self.alpha)\n",
    "    epsilon = 1e-10\n",
    "    alpha = self.alpha\n",
    "    if alpha.device != input.device:\n",
    "      alpha = alpha.to(input.device)\n",
    " \n",
    "    idx = target.cpu().long()\n",
    "    one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n",
    "    one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "    if one_hot_key.device != logit.device:\n",
    "      one_hot_key = one_hot_key.to(logit.device)\n",
    " \n",
    "    if self.smooth:\n",
    "      one_hot_key = torch.clamp(\n",
    "        one_hot_key, self.smooth, 1.0 - self.smooth)\n",
    "    pt = (one_hot_key * logit).sum(1) + epsilon\n",
    "    logpt = pt.log()\n",
    " \n",
    "    gamma = self.gamma\n",
    " \n",
    "    alpha = alpha[idx]\n",
    "    loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    " \n",
    "    if self.size_average:\n",
    "      loss = loss.mean()\n",
    "    else:\n",
    "      loss = loss.sum()\n",
    "    return loss\n",
    " \n",
    " \n",
    " \n",
    "class BCEFocalLoss(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  二分类的Focalloss alpha 固定\n",
    "  \"\"\"\n",
    "  def __init__(self, gamma=2, alpha=0.25, reduction=\"elementwise_mean\"):\n",
    "    super().__init__()\n",
    "    self.gamma = gamma\n",
    "    self.alpha = alpha\n",
    "    self.reduction = reduction\n",
    " \n",
    "  def forward(self, _input, target):\n",
    "    pt = torch.sigmoid(_input)\n",
    "    alpha = self.alpha\n",
    "    loss = - alpha * (1 - pt) ** self.gamma * target * torch.log(pt) - (1 - alpha) * pt ** self.gamma * (1 - target) * torch.log(1 - pt)\n",
    "    if self.reduction == \"elementwise_mean\":\n",
    "      loss = torch.mean(loss)\n",
    "    elif self.reduction == \"sum\":\n",
    "      loss = torch.sum(loss)\n",
    "    return loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Torch Module for GraphSAGE layer\"\"\"\n",
    "# pylint: disable= no-member, arguments-differ, invalid-name\n",
    "\n",
    "class SAGEConv(nn.Module):\n",
    "    r\"\"\"GraphSAGE layer from paper `Inductive Representation Learning on\n",
    "    Large Graphs <https://arxiv.org/pdf/1706.02216.pdf>`__.\n",
    "\n",
    "    .. math::\n",
    "        h_{\\mathcal{N}(i)}^{(l+1)} & = \\mathrm{aggregate}\n",
    "        \\left(\\{h_{j}^{l}, \\forall j \\in \\mathcal{N}(i) \\}\\right)\n",
    "\n",
    "        h_{i}^{(l+1)} & = \\sigma \\left(W \\cdot \\mathrm{concat}\n",
    "        (h_{i}^{l}, h_{\\mathcal{N}(i)}^{l+1} + b) \\right)\n",
    "\n",
    "        h_{i}^{(l+1)} & = \\mathrm{norm}(h_{i}^{l})\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feats : int\n",
    "        Input feature size.\n",
    "    out_feats : int\n",
    "        Output feature size.\n",
    "    feat_drop : float\n",
    "        Dropout rate on features, default: ``0``.\n",
    "    aggregator_type : str\n",
    "        Aggregator type to use (``mean``, ``gcn``, ``pool``, ``lstm``).\n",
    "    bias : bool\n",
    "        If True, adds a learnable bias to the output. Default: ``True``.\n",
    "    norm : callable activation function/layer or None, optional\n",
    "        If not None, applies normalization to the updated node features.\n",
    "    activation : callable activation function/layer or None, optional\n",
    "        If not None, applies an activation function to the updated node features.\n",
    "        Default: ``None``.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 out_feats,\n",
    "                 aggregator_type,\n",
    "                 feat_drop=0.,\n",
    "                 bias=True,\n",
    "                 norm=None,\n",
    "                 activation=None):\n",
    "        super(SAGEConv, self).__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self._aggre_type = aggregator_type\n",
    "        self.norm = norm\n",
    "        self.feat_drop = nn.Dropout(feat_drop)\n",
    "        self.activation = activation\n",
    "        # aggregator type: mean/pool/lstm/gcn\n",
    "        if aggregator_type == 'pool':\n",
    "            self.fc_pool = nn.Linear(in_feats, in_feats)\n",
    "        if aggregator_type == 'gru':\n",
    "            self.gru = nn.GRU(in_feats, in_feats, batch_first=True)\n",
    "        if aggregator_type != 'gcn':\n",
    "            self.fc_self = nn.Linear(in_feats, out_feats, bias=bias)\n",
    "        self.fc_neigh = nn.Linear(in_feats, out_feats, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        if self._aggre_type == 'pool':\n",
    "            nn.init.xavier_uniform_(self.fc_pool.weight, gain=gain)\n",
    "        if self._aggre_type == 'gru':\n",
    "            self.gru.reset_parameters()\n",
    "        if self._aggre_type != 'gcn':\n",
    "            nn.init.xavier_uniform_(self.fc_self.weight, gain=gain)\n",
    "        nn.init.xavier_uniform_(self.fc_neigh.weight, gain=gain)\n",
    "\n",
    "    def _gru_reducer(self, nodes):\n",
    "        \"\"\"LSTM reducer\n",
    "        NOTE(zihao): lstm reducer with default schedule (degree bucketing)\n",
    "        is slow, we could accelerate this with degree padding in the future.\n",
    "        \"\"\"\n",
    "        m = nodes.mailbox['m'] # (B, L, D)\n",
    "        batch_size = m.shape[0]\n",
    "#         h = (m.new_zeros((1, batch_size, self._in_feats)),\n",
    "#              m.new_zeros((1, batch_size, self._in_feats)))\n",
    "        h = m.new_zeros((1, batch_size, self._in_feats))\n",
    "#         _, (rst, _) = self.gru(m, h)\n",
    "        _, rst = self.gru(m, h)\n",
    "        return {'neigh': rst.squeeze(0)}\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        r\"\"\"Compute GraphSAGE layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph : DGLGraph\n",
    "            The graph.\n",
    "        feat : torch.Tensor\n",
    "            The input feature of shape :math:`(N, D_{in})` where :math:`D_{in}`\n",
    "            is size of input feature, :math:`N` is the number of nodes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output feature of shape :math:`(N, D_{out})` where :math:`D_{out}`\n",
    "            is size of output feature.\n",
    "        \"\"\"\n",
    "        graph = graph.local_var()\n",
    "        feat = self.feat_drop(feat)\n",
    "        h_self = feat\n",
    "        if self._aggre_type == 'mean':\n",
    "            graph.ndata['h'] = feat\n",
    "            graph.update_all(fn.copy_src('h', 'm'), fn.mean('m', 'neigh'))\n",
    "            h_neigh = graph.ndata['neigh']\n",
    "        elif self._aggre_type == 'gcn':\n",
    "            graph.ndata['h'] = feat\n",
    "            graph.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'neigh'))\n",
    "            # divide in_degrees\n",
    "            degs = graph.in_degrees().float()\n",
    "            degs = degs.to(feat.device)\n",
    "            h_neigh = (graph.ndata['neigh'] + graph.ndata['h']) / (degs.unsqueeze(-1) + 1)\n",
    "        elif self._aggre_type == 'pool':\n",
    "            graph.ndata['h'] = F.relu(self.fc_pool(feat))\n",
    "            graph.update_all(fn.copy_src('h', 'm'), fn.max('m', 'neigh'))\n",
    "            h_neigh = graph.ndata['neigh']\n",
    "        elif self._aggre_type == 'gru':\n",
    "            graph.ndata['h'] = feat\n",
    "            graph.update_all(fn.copy_src('h', 'm'), self._gru_reducer)\n",
    "            h_neigh = graph.ndata['neigh']\n",
    "        else:\n",
    "            raise KeyError('Aggregator type {} not recognized.'.format(self._aggre_type))\n",
    "        # GraphSAGE GCN does not require fc_self.\n",
    "        if self._aggre_type == 'gcn':\n",
    "            rst = self.fc_neigh(h_neigh)\n",
    "        else:\n",
    "            rst = self.fc_self(h_self) + self.fc_neigh(h_neigh)\n",
    "        # activation\n",
    "        if self.activation is not None:\n",
    "            rst = self.activation(rst)\n",
    "        # normalization\n",
    "        if self.norm is not None:\n",
    "            rst = self.norm(rst)\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, num_heads, hidden_dim, edge_dim, dropout, intent_output_dim, slot_output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim) # 512\n",
    "#         nn.init.kaiming_normal_(self.embedding.weight, mode='fan_out', nonlinearity='relu')\n",
    "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.multiheadAttention = nn.MultiheadAttention(embedding_dim, num_heads, dropout) # 512\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True) # 512\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True, dropout=dropout) # 512\n",
    "        self.gru1 = nn.GRU(embedding_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True) # 512\n",
    "        self.gru2 = nn.GRU(embedding_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True) # 512\n",
    "        self.edge_dim = edge_dim\n",
    "        self.gcn = GCN(embedding_dim, embedding_dim, F.relu)\n",
    "        self.gcn1 = GCN(embedding_dim, 512, F.relu)\n",
    "        self.gcn2 = GCN(512, 1024, F.relu)\n",
    "        self.gatedGraphConv = conv.GatedGraphConv(embedding_dim, 512, 4, 1)\n",
    "        self.gatConv = conv.GATConv(embedding_dim, 64, num_heads=8, residual=True)\n",
    "        self.sageConv = SAGEConv(embedding_dim, embedding_dim, aggregator_type='gru', feat_drop=dropout, activation=F.relu)\n",
    "        self.myGraph = MyGraph(embedding_dim, embedding_dim, 3, dropout)\n",
    "        self.myGat = MyGATLayer(embedding_dim, embedding_dim, dropout)\n",
    "#         self.myGat = MyGATLayer(embedding_dim, embedding_dim, 0.0)\n",
    "        self.selfAttention = ScaledDotProductAttention(dropout)\n",
    "        self.linear1 = nn.Linear(2*hidden_dim, intent_output_dim)\n",
    "        self.linear2 = nn.Linear(2*hidden_dim, slot_output_dim)\n",
    "        self.bilinear1 = nn.Bilinear(embedding_dim, embedding_dim, slot_output_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.dropout4 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        text, text_include_length = x\n",
    "#         print(text.size())\n",
    "#         print(text_include_length.size())\n",
    "#         print(text_include_length-1)\n",
    "#         print(torch.sum(text_include_length-1))\n",
    "#         text_embedding = self.embedding(text)\n",
    "        text_embedding = self.embedding(text)\n",
    "#         print(text_embedding)\n",
    "#         text_embedding = self.linear(text_embedding)\n",
    "        text_embedding = self.dropout1(text_embedding)\n",
    "        text_embedding = self.dropout1(self.linear(text_embedding))\n",
    "#         print(text_embedding)\n",
    "        \n",
    "        # MultiheadAttention\n",
    "#         attn_output, attn_output_weights = self.multiheadAttention(text_embedding.transpose(0, 1), text_embedding.transpose(0, 1), text_embedding.transpose(0, 1), key_padding_mask=_generate_key_padding_mask(text_include_length).to(device))\n",
    "#         attn_output = attn_output.transpose(0, 1)\n",
    "        # TransformerEncoder\n",
    "#         attn_output = self.transformer_encoder(text_embedding.transpose(0, 1), src_key_padding_mask=_generate_key_padding_mask(text_include_length).to(device))\n",
    "#         attn_output = attn_output.transpose(0, 1)\n",
    "        # SelfAttention\n",
    "#         attn_output, _ = self.selfAttention(text_embedding, text_embedding, text_embedding, attn_mask=generate_key_padding_mask(text_include_length).to(device))\n",
    "        \n",
    "        # begin - create dglgraph\n",
    "#         sub_graphs = generate_dglgraph(text, text_include_length, text_edge, text_edge_include_length, text_embedding, edge_embedding)\n",
    "        \n",
    "#         batch_graph = dgl.batch(sub_graphs)\n",
    "        \n",
    "#         batch_graph.update_all(message_func=gnn_msg, reduce_func=gnn_reduce)\n",
    "#         h = dgl.sum_nodes(batch_graph, feat='h')\n",
    "\n",
    "        # end - create dglgraph\n",
    "    \n",
    "    \n",
    "#...............................................................\n",
    "    \n",
    "#         x = out.transpose(0, 1)\n",
    "#         x_intent = torch.max(x, 1)[0]\n",
    "#         x = torch.cat([x[i][:text_include_length[i], :] for i in range(0, len(text_include_length))], dim=0)\n",
    "        \n",
    "#         x_slot = nn.utils.rnn.pack_padded_sequence(text_embedding, lengths=text_include_length, batch_first=True)\n",
    "        \n",
    "        \n",
    "#         print(batch_graph.ndata['h'].size())\n",
    "#         print(x.size())\n",
    "#         print(x_intent.size())\n",
    "\n",
    "        # two lstm\n",
    "        x = nn.utils.rnn.pack_padded_sequence(text_embedding, lengths=text_include_length, batch_first=True)\n",
    "#         output1, hidden1 = self.gru1(x)\n",
    "#         output2, hidden2 = self.gru2(x)\n",
    "\n",
    "        # lstm\n",
    "#         output, (hidden, cell) = self.lstm(x)\n",
    "        # gru\n",
    "        output, hidden = self.gru(x)\n",
    "#         print(output[0].size(), hidden.size())\n",
    "#         pad_output1, _ = nn.utils.rnn.pad_packed_sequence(output1, batch_first=True)\n",
    "        pad_output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "#         print(pad_output)\n",
    "#         x_slot_gru = torch.cat([pad_output[i][:text_include_length[i], :] for i in range(0, len(text_include_length))], dim=0)\n",
    "#         x_intent = torch.max(pad_output, 1)[0]\n",
    "        \n",
    "        # MultiheadAttention\n",
    "#         attn_output, attn_output_weights = self.multiheadAttention(pad_output.transpose(0, 1), pad_output.transpose(0, 1), pad_output.transpose(0, 1), key_padding_mask=_generate_key_padding_mask(text_include_length).to(device))\n",
    "#         pad_output = attn_output.transpose(0, 1)\n",
    "        # SelfAttention\n",
    "#         pad_output_intent, _ = self.selfAttention(pad_output, pad_output, pad_output, attn_mask=generate_key_padding_mask(text_include_length)) # + generate_square_subsequent_mask(pad_output)\n",
    "        # SelfAttention\n",
    "#         pad_output, _ = self.selfAttention(pad_output, pad_output, pad_output, attn_mask=generate_key_padding_mask(text_include_length))\n",
    "#         print(pad_output.size())\n",
    "#         print(attn_output.size())\n",
    "#         pad_output = torch.cat([pad_output, attn_out], dim=2)\n",
    "#         print(pad_output.size())\n",
    "#         pad_output = text_embedding\n",
    "        x_intent = torch.max(pad_output, 1)[0]\n",
    "#         x_intent = torch.mean(pad_output, 1)\n",
    "#         x_intent = torch.sum(pad_output, 1)\n",
    "#         x_intent = torch.cat(tuple([hidden[i] for i in range(hidden.size(0))]), 1)\n",
    "#         print(x.size())\n",
    "#         x_intent = x[:,0]\n",
    "#         x_slot = x[:, 1:]\n",
    "#         print(x_intent.size())\n",
    "#         print(x_slot.size())\n",
    "#         x_slot = torch.cat([pad_output[i][:text_include_length[i], :] for i in range(0, len(text_include_length))], dim=0)\n",
    "#         print(x_slot.data.size())\n",
    "#         x_intent = F.dropout(hidden.view(hidden.size(1), -1), p=dropout)\n",
    "    \n",
    "#...............................................................     \n",
    "        sub_graphs = generate_dglgraph(pad_output, x_intent, text_include_length)\n",
    "        batch_graph = dgl.batch(sub_graphs)\n",
    "#         etypes = torch.tensor([0]*(np.sum(batch_graph.batch_num_edges)))\n",
    "#         x = self.gatedGraphConv(batch_graph, batch_graph.ndata['h'], etypes)\n",
    "#         x = self.gatConv(batch_graph, batch_graph.ndata['h'])\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.sageConv(batch_graph, batch_graph.ndata['h'])\n",
    "        x = self.myGat(batch_graph, batch_graph.ndata['h'])\n",
    "#         x = self.gcn(batch_graph, batch_graph.ndata['h'])\n",
    "#         feats = batch_graph.ndata['h']\n",
    "#         etypes = batch_graph.edata['etype']\n",
    "#         x = self.myGraph(batch_graph, feats, etypes)\n",
    "#         x = self.myGraph(batch_graph, x, etypes)\n",
    "#         print('x', x)\n",
    "#         print(x.size())\n",
    "#         print(output[0] == x)\n",
    "#         batch_graph.ndata['h'] = x\n",
    "#         x_intent = dgl.max_nodes(batch_graph, feat='h')\n",
    "#         print(x_intent.size())\n",
    "#         print(batch_graph.batch_size, batch_graph.batch_num_nodes)\n",
    "#         unbatch_graph = dgl.unbatch(batch_graph)\n",
    "#         print(unbatch_graph)\n",
    "        \n",
    "\n",
    "#...............................................................        \n",
    "#         sub_graphs = generate_dglgraph(x, text_include_length)\n",
    "#         batch_graph = dgl.batch(sub_graphs)\n",
    "#         x = self.gcn1(batch_graph, None)\n",
    "#         x = self.gcn2(batch_graph, x)\n",
    "\n",
    "#         batch_graph.ndata['h'] = x\n",
    "#         x_intent = dgl.max_nodes(batch_graph, feat='h')\n",
    "#         print(batch_graph.batch_size, batch_graph.batch_num_nodes)\n",
    "#         unbatch_graph = dgl.unbatch(batch_graph)\n",
    "#         print(unbatch_graph)\n",
    "\n",
    "#...............................................................\n",
    "        packed_sequence = nn.utils.rnn.PackedSequence(data=x, batch_sizes=torch.tensor(batch_graph.batch_num_nodes))\n",
    "        x = nn.utils.rnn.pad_packed_sequence(packed_sequence, batch_first=False)[0]\n",
    "#         print('x', x)\n",
    "#         print(x[0].size())\n",
    "        x_intent = x[:,0]\n",
    "#         x_intent = torch.cat([x[:,0], x_intent], dim=1)\n",
    "        x_slot = x[:, 1:]\n",
    "#         x_slot = torch.cat([x[:,1:], pad_output], dim=2)\n",
    "#         print(x_intent.size())\n",
    "#         print(x_slot.size())\n",
    "#         text_include_length = text_include_length-1\n",
    "        x_slot = torch.cat([x_slot[i][:text_include_length[i], :] for i in range(0, len(text_include_length))], dim=0)\n",
    "#         x_slot = nn.utils.rnn.pack_padded_sequence(x_slot, lengths=text_include_length-1, batch_first=True)\n",
    "#         print(x_slot[0].size())\n",
    "\n",
    "        \n",
    "        # lstm\n",
    "#         x = nn.utils.rnn.pack_padded_sequence(x_slot, lengths=text_include_length, batch_first=True)\n",
    "#         output, (hidden, cell) = self.lstm(x)\n",
    "        # gru\n",
    "#         output, hidden = self.gru1(x)\n",
    "#         print(output[0].size(), hidden.size())\n",
    "#         pad_output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "#         print(pad_output)\n",
    "#         x_intent = torch.max(pad_output, 1)[0]\n",
    "#         x_slot = torch.cat([pad_output[i][:text_include_length[i], :] for i in range(0, len(text_include_length))], dim=0)\n",
    "    \n",
    "    \n",
    "        \n",
    "        x_intent = self.dropout1(x_intent)\n",
    "        x_intent = F.relu(x_intent)\n",
    "        x_intent = self.linear1(x_intent)\n",
    "        \n",
    "#         x_slot_gru = F.dropout(x_slot_gru, p=dropout)\n",
    "#         x_slot_gru = F.relu(x_slot_gru)\n",
    "        \n",
    "        x_slot = self.dropout1(x_slot)\n",
    "#         x_slot = F.dropout(x, p= dropout)\n",
    "#         x_slot = F.dropout(x_slot, p= dropout)\n",
    "        x_slot = F.relu(x_slot)\n",
    "        x_slot = self.linear2(x_slot)\n",
    "#         x_slot = self.bilinear1(x_slot, x_slot_gru)\n",
    "        \n",
    "        return x_intent, x_slot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.26666666666666666\n",
      "True False\n",
      "0.75\n",
      "torch.Size([3, 1]) [[1], [2], [3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def acc(y_pred, y_true):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "def f_score(y_pred, y_true):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "def semantic_acc(semantic_slot_pred, semantic_slot_true, semantic_intent_pred, semantic_intent_true):\n",
    "    num_acc = 0\n",
    "    for i in range(len(semantic_slot_pred)):\n",
    "        num_acc += (semantic_slot_pred[i] == semantic_slot_true[i] and semantic_intent_pred[i] == semantic_intent_true[i])\n",
    "    return num_acc / len(semantic_slot_pred)\n",
    "    \n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "print(acc(y_pred, y_true))\n",
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "print(f_score(y_pred, y_true))\n",
    "y_pred = [[1,2],[0,1],[1,3],[2,3]]\n",
    "y_true = [[1,2],[0,1],[1,4],[2,3]]\n",
    "y_intent_pred = [1,2,3,4]\n",
    "y_intent_true = [1,2,3,4]\n",
    "print(y_pred[0] == y_true[0], y_pred[2] == y_true[2])\n",
    "print(semantic_acc(y_pred, y_true, y_intent_pred, y_intent_true))\n",
    "\n",
    "x = torch.tensor([[1],[2],[3]])\n",
    "print(x.size(), x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3], [4], [5]], [[1, 2, 4], [5], [6]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_semantic_slot(semantic_slot_pred, semantic_slot_true, include_length):\n",
    "    semantic_pred = []\n",
    "    semantic_true = []\n",
    "    i = 0\n",
    "    for l in include_length:\n",
    "        semantic_pred.append(semantic_slot_pred[i:i+l])\n",
    "        semantic_true.append(semantic_slot_true[i:i+l])\n",
    "        i += l\n",
    "    return semantic_pred, semantic_true\n",
    "\n",
    "semantic_slot_pred = [1, 2, 3, 4, 5]\n",
    "semantic_slot_true = [1, 2, 4, 5, 6]\n",
    "include_lenght = [3, 1, 1]\n",
    "# print(semantic_slot_pred[0:2])\n",
    "process_semantic_slot(semantic_slot_pred, semantic_slot_true, include_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, \n",
    "          iterator: data.BucketIterator, \n",
    "          optimizer: optim.Optimizer,\n",
    "#           scheduler: optim.lr_scheduler,\n",
    "          criterion: nn.Module, \n",
    "          clip: float):\n",
    "    \n",
    "    model.train()\n",
    "    intent_train_loss = 0\n",
    "    slot_train_loss = 0\n",
    "    intent_train_pred = []\n",
    "    slot_train_pred = []\n",
    "    intent_train_true = []\n",
    "    slot_train_true = []\n",
    "    semantic_slot_train_pred = []\n",
    "    semantic_slot_train_true = []\n",
    "    \n",
    "    for _, batch in enumerate(iterator):\n",
    "        text = batch.text\n",
    "        slot_target, slot_include_length = batch.slot\n",
    "        \n",
    "        intent_target = batch.intent.squeeze(1)\n",
    "#         slot_target = nn.utils.rnn.pack_padded_sequence(slot_target, slot_include_length, batch_first=True)[0].view(-1)\n",
    "        slot_target = torch.cat([slot_target[i][:slot_include_length[i]] for i in range(0, len(slot_include_length))], dim=0)\n",
    "#         print(intent_target.size(), slot_target.size())\n",
    "        \n",
    "        intent_output, slot_output = model(text)\n",
    "\n",
    "#         print(intent_output.size(), slot_output.size())\n",
    "        \n",
    "        intent_loss = criterion(intent_output, intent_target)\n",
    "        slot_loss = criterion(slot_output, slot_target)\n",
    "        loss = 0.1*intent_loss + 0.9*slot_loss # loss = 0.1*intent_loss + 0.9*slot_loss => ATIS Datasets\n",
    "        \n",
    "        \n",
    "        intent_train_loss += intent_loss.item()\n",
    "        intent_output = [INTENT_LABEL.vocab.itos[elem] for elem in intent_output.argmax(1)]\n",
    "        intent_train_pred += intent_output\n",
    "        intent_target = [INTENT_LABEL.vocab.itos[elem] for elem in intent_target]\n",
    "        intent_train_true += intent_target\n",
    "        \n",
    "        slot_train_loss += slot_loss.item()\n",
    "        slot_output = [SLOT_LABEL.vocab.itos[elem] for elem in slot_output.argmax(1)]\n",
    "        slot_train_pred += slot_output\n",
    "        slot_target = [SLOT_LABEL.vocab.itos[elem] for elem in slot_target]\n",
    "        slot_train_true += slot_target\n",
    "        \n",
    "        semantic_slot_pred, semantic_slot_true = process_semantic_slot(slot_output, slot_target, slot_include_length)\n",
    "        semantic_slot_train_pred += semantic_slot_pred\n",
    "        semantic_slot_train_true += semantic_slot_true\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "    \n",
    "#     print(intent_train_pred)\n",
    "#     print(intent_train_true)\n",
    "    sem_acc = semantic_acc(semantic_slot_train_pred, semantic_slot_train_true, intent_train_pred, intent_train_true)\n",
    "    return intent_train_loss / len(iterator), acc(intent_train_pred, intent_train_true), slot_train_loss / len(iterator), computeF1Score(semantic_slot_train_true, semantic_slot_train_pred)[0], sem_acc\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: data.BucketIterator,\n",
    "             criterion: nn.Module):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_intent_loss = 0\n",
    "    epoch_slot_loss = 0\n",
    "    epoch_intent_pred = []\n",
    "    epoch_slot_pred = []\n",
    "    epoch_intent_true = []\n",
    "    epoch_slot_true = []\n",
    "    epoch_semantic_slot_pred = []\n",
    "    epoch_semantic_slot_true = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for _, batch in enumerate(iterator):\n",
    "            text = batch.text\n",
    "            slot_target, slot_include_length = batch.slot\n",
    "        \n",
    "            intent_target = batch.intent.squeeze(1)\n",
    "#             slot_target = nn.utils.rnn.pack_padded_sequence(slot_target, slot_include_length, batch_first=True)[0].view(-1)\n",
    "            slot_target = torch.cat([slot_target[i][:slot_include_length[i]] for i in range(0, len(slot_include_length))], dim=0)\n",
    "            \n",
    "            intent_output, slot_output = model(text)\n",
    "            \n",
    "            intent_loss = criterion(intent_output, intent_target)\n",
    "            slot_loss = criterion(slot_output, slot_target)\n",
    "            \n",
    "            epoch_intent_loss += intent_loss.item()\n",
    "            intent_output = [INTENT_LABEL.vocab.itos[elem] for elem in intent_output.argmax(1)]\n",
    "            epoch_intent_pred += intent_output\n",
    "            intent_target = [INTENT_LABEL.vocab.itos[elem] for elem in intent_target]\n",
    "            epoch_intent_true += intent_target\n",
    "        \n",
    "            epoch_slot_loss += slot_loss.item()\n",
    "            slot_output = [SLOT_LABEL.vocab.itos[elem] for elem in slot_output.argmax(1)]\n",
    "            epoch_slot_pred += slot_output\n",
    "            slot_target = [SLOT_LABEL.vocab.itos[elem] for elem in slot_target]\n",
    "            epoch_slot_true += slot_target\n",
    "            \n",
    "            semantic_slot_pred, semantic_slot_true = process_semantic_slot(slot_output, slot_target, slot_include_length)\n",
    "            epoch_semantic_slot_pred += semantic_slot_pred\n",
    "            epoch_semantic_slot_true += semantic_slot_true\n",
    "        \n",
    "#     print('semantic_slot_pred', semantic_slot_pred)\n",
    "#     print('semantic_slot_true', semantic_slot_true)\n",
    "    sem_acc = semantic_acc(epoch_semantic_slot_pred, epoch_semantic_slot_true, epoch_intent_pred, epoch_intent_true)\n",
    "    \n",
    "    return epoch_intent_loss / len(iterator), acc(epoch_intent_pred, epoch_intent_true), epoch_slot_loss / len(iterator), computeF1Score(epoch_semantic_slot_true, epoch_semantic_slot_pred)[0], sem_acc\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "              end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 1.019 | Train Intent Acc: 75.39% \t Train Slot Loss: 0.774 | Train Slot F1 Score: 63.83% \t Train Semantic Score: 28.83%\n",
      "\tVal Intent Loss: 0.874 |  Val Intent Acc: 78.00% \t Val Slot Loss: 0.271 |  Val Slot F1 Score: 82.65% \t Val Semantic Score: 47.40%\n",
      "\tTest Intent Loss: 0.993 | Test Intent Acc: 77.60% \t Test Slot Loss: 0.319 | Test Slot F1 Score: 82.57% \t Test Semantic Score: 50.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type GCN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NodeApplyModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SAGEConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MyGraph. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ReduceApplyModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MyGATLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ScaledDotProductAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.589 | Train Intent Acc: 85.17% \t Train Slot Loss: 0.161 | Train Slot F1 Score: 89.92% \t Train Semantic Score: 65.59%\n",
      "\tVal Intent Loss: 0.551 |  Val Intent Acc: 86.60% \t Val Slot Loss: 0.121 |  Val Slot F1 Score: 92.21% \t Val Semantic Score: 71.60%\n",
      "\tTest Intent Loss: 0.632 | Test Intent Acc: 86.56% \t Test Slot Loss: 0.172 | Test Slot F1 Score: 91.76% \t Test Semantic Score: 72.34%\n",
      "Epoch: 03 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.372 | Train Intent Acc: 91.13% \t Train Slot Loss: 0.073 | Train Slot F1 Score: 95.26% \t Train Semantic Score: 80.62%\n",
      "\tVal Intent Loss: 0.360 |  Val Intent Acc: 90.00% \t Val Slot Loss: 0.078 |  Val Slot F1 Score: 94.92% \t Val Semantic Score: 77.80%\n",
      "\tTest Intent Loss: 0.433 | Test Intent Acc: 88.02% \t Test Slot Loss: 0.128 | Test Slot F1 Score: 94.33% \t Test Semantic Score: 77.04%\n",
      "Epoch: 04 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.242 | Train Intent Acc: 93.95% \t Train Slot Loss: 0.040 | Train Slot F1 Score: 97.58% \t Train Semantic Score: 87.92%\n",
      "\tVal Intent Loss: 0.298 |  Val Intent Acc: 92.60% \t Val Slot Loss: 0.062 |  Val Slot F1 Score: 96.13% \t Val Semantic Score: 82.40%\n",
      "\tTest Intent Loss: 0.362 | Test Intent Acc: 91.15% \t Test Slot Loss: 0.108 | Test Slot F1 Score: 94.67% \t Test Semantic Score: 79.62%\n",
      "Epoch: 05 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.168 | Train Intent Acc: 96.25% \t Train Slot Loss: 0.025 | Train Slot F1 Score: 98.53% \t Train Semantic Score: 92.45%\n",
      "\tVal Intent Loss: 0.255 |  Val Intent Acc: 94.40% \t Val Slot Loss: 0.052 |  Val Slot F1 Score: 96.55% \t Val Semantic Score: 85.00%\n",
      "\tTest Intent Loss: 0.303 | Test Intent Acc: 92.72% \t Test Slot Loss: 0.114 | Test Slot F1 Score: 95.33% \t Test Semantic Score: 81.97%\n",
      "Epoch: 06 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.116 | Train Intent Acc: 97.74% \t Train Slot Loss: 0.017 | Train Slot F1 Score: 98.88% \t Train Semantic Score: 94.69%\n",
      "\tVal Intent Loss: 0.185 |  Val Intent Acc: 96.00% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 96.81% \t Val Semantic Score: 87.00%\n",
      "\tTest Intent Loss: 0.267 | Test Intent Acc: 91.60% \t Test Slot Loss: 0.118 | Test Slot F1 Score: 95.59% \t Test Semantic Score: 80.96%\n",
      "Epoch: 07 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.083 | Train Intent Acc: 98.41% \t Train Slot Loss: 0.012 | Train Slot F1 Score: 99.31% \t Train Semantic Score: 96.40%\n",
      "\tVal Intent Loss: 0.192 |  Val Intent Acc: 96.20% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.14% \t Val Semantic Score: 88.20%\n",
      "\tTest Intent Loss: 0.223 | Test Intent Acc: 94.18% \t Test Slot Loss: 0.121 | Test Slot F1 Score: 95.40% \t Test Semantic Score: 82.98%\n",
      "Epoch: 08 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.062 | Train Intent Acc: 98.86% \t Train Slot Loss: 0.008 | Train Slot F1 Score: 99.52% \t Train Semantic Score: 97.32%\n",
      "\tVal Intent Loss: 0.159 |  Val Intent Acc: 96.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.17% \t Val Semantic Score: 88.40%\n",
      "\tTest Intent Loss: 0.179 | Test Intent Acc: 94.62% \t Test Slot Loss: 0.127 | Test Slot F1 Score: 95.52% \t Test Semantic Score: 83.65%\n",
      "Epoch: 09 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.045 | Train Intent Acc: 99.17% \t Train Slot Loss: 0.006 | Train Slot F1 Score: 99.67% \t Train Semantic Score: 98.17%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.19% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.162 | Test Intent Acc: 95.97% \t Test Slot Loss: 0.124 | Test Slot F1 Score: 95.80% \t Test Semantic Score: 85.44%\n",
      "Epoch: 10 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.033 | Train Intent Acc: 99.55% \t Train Slot Loss: 0.005 | Train Slot F1 Score: 99.74% \t Train Semantic Score: 98.70%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.037 |  Val Slot F1 Score: 97.42% \t Val Semantic Score: 88.80%\n",
      "\tTest Intent Loss: 0.145 | Test Intent Acc: 96.86% \t Test Slot Loss: 0.123 | Test Slot F1 Score: 95.67% \t Test Semantic Score: 85.89%\n",
      "Epoch: 11 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.027 | Train Intent Acc: 99.62% \t Train Slot Loss: 0.003 | Train Slot F1 Score: 99.85% \t Train Semantic Score: 99.04%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.037 |  Val Slot F1 Score: 97.48% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.139 | Test Intent Acc: 96.75% \t Test Slot Loss: 0.123 | Test Slot F1 Score: 95.64% \t Test Semantic Score: 86.00%\n",
      "Epoch: 12 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.024 | Train Intent Acc: 99.73% \t Train Slot Loss: 0.003 | Train Slot F1 Score: 99.81% \t Train Semantic Score: 99.20%\n",
      "\tVal Intent Loss: 0.120 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.038 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.137 | Test Intent Acc: 96.98% \t Test Slot Loss: 0.132 | Test Slot F1 Score: 95.65% \t Test Semantic Score: 85.89%\n",
      "Epoch: 13 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.019 | Train Intent Acc: 99.75% \t Train Slot Loss: 0.003 | Train Slot F1 Score: 99.89% \t Train Semantic Score: 99.33%\n",
      "\tVal Intent Loss: 0.119 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.038 |  Val Slot F1 Score: 97.43% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.139 | Test Intent Acc: 96.75% \t Test Slot Loss: 0.130 | Test Slot F1 Score: 95.63% \t Test Semantic Score: 85.89%\n",
      "Epoch: 14 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.017 | Train Intent Acc: 99.73% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.93% \t Train Semantic Score: 99.42%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.130 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.133 | Test Slot F1 Score: 95.50% \t Test Semantic Score: 86.00%\n",
      "Epoch: 15 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.013 | Train Intent Acc: 99.82% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.95% \t Train Semantic Score: 99.55%\n",
      "\tVal Intent Loss: 0.121 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.137 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.134 | Test Slot F1 Score: 95.56% \t Test Semantic Score: 85.89%\n",
      "Epoch: 16 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.011 | Train Intent Acc: 99.87% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.93% \t Train Semantic Score: 99.58%\n",
      "\tVal Intent Loss: 0.122 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.037 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.134 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.132 | Test Slot F1 Score: 95.70% \t Test Semantic Score: 86.79%\n",
      "Epoch: 17 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.011 | Train Intent Acc: 99.87% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.71%\n",
      "\tVal Intent Loss: 0.123 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.134 | Test Slot F1 Score: 95.61% \t Test Semantic Score: 86.90%\n",
      "Epoch: 18 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.009 | Train Intent Acc: 99.96% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.78%\n",
      "\tVal Intent Loss: 0.123 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.52% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.135 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.140 | Test Slot F1 Score: 95.60% \t Test Semantic Score: 86.34%\n",
      "Epoch: 19 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.007 | Train Intent Acc: 99.93% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.73%\n",
      "\tVal Intent Loss: 0.122 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.134 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.137 | Test Slot F1 Score: 95.69% \t Test Semantic Score: 86.45%\n",
      "Epoch: 20 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.007 | Train Intent Acc: 99.96% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.80%\n",
      "\tVal Intent Loss: 0.118 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.144 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.140 | Test Slot F1 Score: 95.82% \t Test Semantic Score: 87.01%\n",
      "Epoch: 21 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.006 | Train Intent Acc: 99.96% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.80%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.131 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.140 | Test Slot F1 Score: 95.78% \t Test Semantic Score: 86.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.005 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.134 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.141 | Test Slot F1 Score: 95.70% \t Test Semantic Score: 86.79%\n",
      "Epoch: 23 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.004 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.125 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.134 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.141 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 86.90%\n",
      "Epoch: 24 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.004 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.82%\n",
      "\tVal Intent Loss: 0.123 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.92% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.137 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 95.73% \t Test Semantic Score: 86.45%\n",
      "Epoch: 25 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.004 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.84%\n",
      "\tVal Intent Loss: 0.126 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.037 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.136 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.142 | Test Slot F1 Score: 95.71% \t Test Semantic Score: 86.79%\n",
      "Epoch: 26 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.004 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.122 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.95% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 95.70% \t Test Semantic Score: 86.56%\n",
      "Epoch: 27 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.82%\n",
      "\tVal Intent Loss: 0.125 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.137 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.143 | Test Slot F1 Score: 95.80% \t Test Semantic Score: 87.01%\n",
      "Epoch: 28 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.95% \t Train Semantic Score: 99.75%\n",
      "\tVal Intent Loss: 0.118 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.140 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.144 | Test Slot F1 Score: 95.91% \t Test Semantic Score: 86.79%\n",
      "Epoch: 29 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.82%\n",
      "\tVal Intent Loss: 0.125 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.139 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.146 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 87.01%\n",
      "Epoch: 30 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.124 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.92% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.140 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.144 | Test Slot F1 Score: 95.76% \t Test Semantic Score: 86.90%\n",
      "Epoch: 31 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.126 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.141 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.93% \t Test Semantic Score: 87.01%\n",
      "Epoch: 32 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.129 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.139 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 95.83% \t Test Semantic Score: 86.67%\n",
      "Epoch: 33 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.121 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.144 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 95.83% \t Test Semantic Score: 87.01%\n",
      "Epoch: 34 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.123 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.86% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.12%\n",
      "Epoch: 35 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.125 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.145 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 95.82% \t Test Semantic Score: 87.01%\n",
      "Epoch: 36 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.87%\n",
      "\tVal Intent Loss: 0.127 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.041 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.141 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.12%\n",
      "Epoch: 37 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.041 |  Val Slot F1 Score: 97.95% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.139 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.01%\n",
      "Epoch: 38 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.84%\n",
      "\tVal Intent Loss: 0.129 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.142 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 95.93% \t Test Semantic Score: 86.67%\n",
      "Epoch: 39 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.94% \t Train Semantic Score: 99.71%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.144 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.141 | Test Slot F1 Score: 95.78% \t Test Semantic Score: 86.45%\n",
      "Epoch: 40 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.95% \t Train Semantic Score: 99.75%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.46% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.131 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.142 | Test Slot F1 Score: 95.79% \t Test Semantic Score: 86.56%\n",
      "Epoch: 41 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.87%\n",
      "\tVal Intent Loss: 0.119 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.54% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 95.73% \t Test Semantic Score: 86.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.95% \t Train Semantic Score: 99.80%\n",
      "\tVal Intent Loss: 0.116 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.34% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.141 | Test Slot F1 Score: 95.78% \t Test Semantic Score: 86.79%\n",
      "Epoch: 43 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.91% \t Train Semantic Score: 99.49%\n",
      "\tVal Intent Loss: 0.103 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.050 |  Val Slot F1 Score: 97.03% \t Val Semantic Score: 88.40%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 94.89% \t Test Semantic Score: 83.65%\n",
      "Epoch: 44 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.050 | Train Intent Acc: 98.73% \t Train Slot Loss: 0.015 | Train Slot F1 Score: 98.94% \t Train Semantic Score: 95.18%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.056 |  Val Slot F1 Score: 96.82% \t Val Semantic Score: 87.60%\n",
      "\tTest Intent Loss: 0.160 | Test Intent Acc: 96.30% \t Test Slot Loss: 0.143 | Test Slot F1 Score: 95.10% \t Test Semantic Score: 83.76%\n",
      "Epoch: 45 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.045 | Train Intent Acc: 98.84% \t Train Slot Loss: 0.014 | Train Slot F1 Score: 98.96% \t Train Semantic Score: 95.65%\n",
      "\tVal Intent Loss: 0.119 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.33% \t Val Semantic Score: 88.80%\n",
      "\tTest Intent Loss: 0.145 | Test Intent Acc: 96.53% \t Test Slot Loss: 0.123 | Test Slot F1 Score: 95.39% \t Test Semantic Score: 85.44%\n",
      "Epoch: 46 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.021 | Train Intent Acc: 99.44% \t Train Slot Loss: 0.008 | Train Slot F1 Score: 99.47% \t Train Semantic Score: 97.70%\n",
      "\tVal Intent Loss: 0.121 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.038 |  Val Slot F1 Score: 97.45% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.121 | Test Slot F1 Score: 95.98% \t Test Semantic Score: 86.67%\n",
      "Epoch: 47 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.009 | Train Intent Acc: 99.82% \t Train Slot Loss: 0.003 | Train Slot F1 Score: 99.80% \t Train Semantic Score: 99.00%\n",
      "\tVal Intent Loss: 0.130 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.43% \t Val Semantic Score: 89.00%\n",
      "\tTest Intent Loss: 0.134 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.128 | Test Slot F1 Score: 95.69% \t Test Semantic Score: 86.23%\n",
      "Epoch: 48 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.008 | Train Intent Acc: 99.87% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.87% \t Train Semantic Score: 99.44%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.49% \t Val Semantic Score: 89.20%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.132 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 86.90%\n",
      "Epoch: 49 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.004 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.94% \t Train Semantic Score: 99.80%\n",
      "\tVal Intent Loss: 0.127 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.041 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.142 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.135 | Test Slot F1 Score: 95.96% \t Test Semantic Score: 87.01%\n",
      "Epoch: 50 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.84%\n",
      "\tVal Intent Loss: 0.124 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.136 | Test Slot F1 Score: 95.98% \t Test Semantic Score: 87.23%\n",
      "Epoch: 51 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.041 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.138 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.137 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.35%\n",
      "Epoch: 52 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.145 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.140 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.23%\n",
      "Epoch: 53 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.145 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.140 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.46%\n",
      "Epoch: 54 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.144 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.142 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.35%\n",
      "Epoch: 55 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.142 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.35%\n",
      "Epoch: 56 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.143 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.23%\n",
      "Epoch: 57 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.143 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.23%\n",
      "Epoch: 58 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 96.09% \t Test Semantic Score: 87.35%\n",
      "Epoch: 59 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 96.11% \t Test Semantic Score: 87.46%\n",
      "Epoch: 60 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.144 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.144 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.12%\n",
      "Epoch: 61 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.146 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.12%\n",
      "Epoch: 63 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.146 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.12%\n",
      "Epoch: 64 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.60% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.145 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 65 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 66 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 100.00%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 67 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.143 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 68 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 69 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.23%\n",
      "Epoch: 70 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 71 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.23%\n",
      "Epoch: 72 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.86% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.23%\n",
      "Epoch: 73 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.23%\n",
      "Epoch: 74 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.06% \t Test Semantic Score: 87.23%\n",
      "Epoch: 75 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.12%\n",
      "Epoch: 76 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.12%\n",
      "Epoch: 77 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.23%\n",
      "Epoch: 78 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.12%\n",
      "Epoch: 79 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.152 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.12%\n",
      "Epoch: 80 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.12%\n",
      "Epoch: 81 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.23%\n",
      "Epoch: 83 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.149 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.01%\n",
      "Epoch: 84 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.96% \t Test Semantic Score: 86.90%\n",
      "Epoch: 85 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.01%\n",
      "Epoch: 86 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.01%\n",
      "Epoch: 87 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.96% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.01%\n",
      "Epoch: 88 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.131 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.83% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.12%\n",
      "Epoch: 89 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.146 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.01%\n",
      "Epoch: 90 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 96.11% \t Test Semantic Score: 87.23%\n",
      "Epoch: 91 | Time: 0m 19s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 86.90%\n",
      "Epoch: 92 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 86.90%\n",
      "Epoch: 93 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.01%\n",
      "Epoch: 94 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.01%\n",
      "Epoch: 95 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.12%\n",
      "Epoch: 96 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.83% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 96.04% \t Test Semantic Score: 87.23%\n",
      "Epoch: 97 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.12%\n",
      "Epoch: 98 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.154 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.152 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.12%\n",
      "Epoch: 99 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.01%\n",
      "Epoch: 100 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.01%\n",
      "Epoch: 101 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.153 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 86.67%\n",
      "Epoch: 103 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.142 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 86.90%\n",
      "Epoch: 104 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.87%\n",
      "\tVal Intent Loss: 0.142 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.144 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.77% \t Test Semantic Score: 86.67%\n",
      "Epoch: 105 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.154 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.84% \t Test Semantic Score: 86.79%\n",
      "Epoch: 106 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.92% \t Val Semantic Score: 91.00%\n",
      "\tTest Intent Loss: 0.156 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.153 | Test Slot F1 Score: 95.96% \t Test Semantic Score: 87.23%\n",
      "Epoch: 107 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.92% \t Val Semantic Score: 91.00%\n",
      "\tTest Intent Loss: 0.143 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.82% \t Test Semantic Score: 86.67%\n",
      "Epoch: 108 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.146 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.12%\n",
      "Epoch: 109 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.143 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.92% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.154 | Test Slot F1 Score: 95.85% \t Test Semantic Score: 86.56%\n",
      "Epoch: 110 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.142 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.98% \t Test Semantic Score: 87.01%\n",
      "Epoch: 111 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.87%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.041 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.12%\n",
      "Epoch: 112 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.153 | Test Slot F1 Score: 95.80% \t Test Semantic Score: 86.67%\n",
      "Epoch: 113 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.86% \t Val Semantic Score: 90.60%\n",
      "\tTest Intent Loss: 0.155 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.98% \t Test Semantic Score: 87.01%\n",
      "Epoch: 114 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.040 |  Val Slot F1 Score: 98.01% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.155 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 86.79%\n",
      "Epoch: 115 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.23%\n",
      "Epoch: 116 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 98.10% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.23%\n",
      "Epoch: 117 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.144 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 86.79%\n",
      "Epoch: 118 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.95% \t Train Semantic Score: 99.84%\n",
      "\tVal Intent Loss: 0.121 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 98.01% \t Val Semantic Score: 90.80%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 95.91% \t Test Semantic Score: 87.01%\n",
      "Epoch: 119 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.93% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.73%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.00% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.132 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.147 | Test Slot F1 Score: 95.73% \t Test Semantic Score: 86.67%\n",
      "Epoch: 120 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.006 | Train Intent Acc: 99.87% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.75%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.049 |  Val Slot F1 Score: 97.64% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.181 | Test Intent Acc: 96.98% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.72% \t Test Semantic Score: 86.23%\n",
      "Epoch: 125 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.007 | Train Intent Acc: 99.84% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.86% \t Train Semantic Score: 99.31%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.152 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.145 | Test Slot F1 Score: 95.73% \t Test Semantic Score: 86.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.004 | Train Intent Acc: 99.93% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.91% \t Train Semantic Score: 99.51%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.31% \t Val Semantic Score: 88.80%\n",
      "\tTest Intent Loss: 0.150 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.144 | Test Slot F1 Score: 95.66% \t Test Semantic Score: 87.01%\n",
      "Epoch: 127 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.003 | Train Intent Acc: 99.96% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.78%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.37% \t Val Semantic Score: 89.00%\n",
      "\tTest Intent Loss: 0.142 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.146 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.46%\n",
      "Epoch: 128 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.125 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.58% \t Val Semantic Score: 89.20%\n",
      "\tTest Intent Loss: 0.153 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.57%\n",
      "Epoch: 129 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.130 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.60% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 87.35%\n",
      "Epoch: 130 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.130 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.55% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.147 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.35%\n",
      "Epoch: 131 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.130 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.148 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.152 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.23%\n",
      "Epoch: 132 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.55% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.151 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.35%\n",
      "Epoch: 133 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.131 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.155 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.152 | Test Slot F1 Score: 96.09% \t Test Semantic Score: 87.57%\n",
      "Epoch: 134 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.96% \t Train Semantic Score: 99.84%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.155 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.154 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.23%\n",
      "Epoch: 135 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.58% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.158 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.153 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.46%\n",
      "Epoch: 136 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.55% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.157 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.153 | Test Slot F1 Score: 96.03% \t Test Semantic Score: 87.46%\n",
      "Epoch: 137 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.52% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.156 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.35%\n",
      "Epoch: 138 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.131 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.40% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.160 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.156 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 87.01%\n",
      "Epoch: 139 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.132 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.40% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.160 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.23%\n",
      "Epoch: 140 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.40% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.160 | Test Intent Acc: 97.54% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.01%\n",
      "Epoch: 141 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.43% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.156 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.155 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.23%\n",
      "Epoch: 142 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.52% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.159 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.23%\n",
      "Epoch: 143 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.49% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.161 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.156 | Test Slot F1 Score: 95.95% \t Test Semantic Score: 87.23%\n",
      "Epoch: 144 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.54% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.160 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.23%\n",
      "Epoch: 145 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.46% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.161 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.52% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.164 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.12%\n",
      "Epoch: 147 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.60% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.156 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.23%\n",
      "Epoch: 148 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.136 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.047 |  Val Slot F1 Score: 97.55% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.12%\n",
      "Epoch: 149 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.047 |  Val Slot F1 Score: 97.55% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.164 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 87.01%\n",
      "Epoch: 150 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.60% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 87.01%\n",
      "Epoch: 151 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.046 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.161 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.88% \t Test Semantic Score: 87.12%\n",
      "Epoch: 152 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.162 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.99% \t Test Semantic Score: 87.01%\n",
      "Epoch: 153 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.92% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.162 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.12%\n",
      "Epoch: 154 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.142 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.98% \t Val Semantic Score: 90.40%\n",
      "\tTest Intent Loss: 0.156 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.160 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.23%\n",
      "Epoch: 155 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.161 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 87.12%\n",
      "Epoch: 156 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.12%\n",
      "Epoch: 157 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.143 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.164 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.12%\n",
      "Epoch: 158 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.166 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.161 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.12%\n",
      "Epoch: 159 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 86.90%\n",
      "Epoch: 160 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.166 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.161 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 86.90%\n",
      "Epoch: 161 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.168 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.88% \t Test Semantic Score: 87.01%\n",
      "Epoch: 162 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.89% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.167 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.88% \t Test Semantic Score: 86.90%\n",
      "Epoch: 163 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.01%\n",
      "Epoch: 164 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.166 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 86.90%\n",
      "Epoch: 165 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.168 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.160 | Test Slot F1 Score: 95.85% \t Test Semantic Score: 86.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 166 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.168 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.01%\n",
      "Epoch: 167 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.167 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 86.90%\n",
      "Epoch: 168 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.170 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 87.01%\n",
      "Epoch: 169 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.87% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.168 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.12%\n",
      "Epoch: 170 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.84% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.170 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.160 | Test Slot F1 Score: 95.96% \t Test Semantic Score: 87.23%\n",
      "Epoch: 171 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.86% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.172 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.160 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.23%\n",
      "Epoch: 172 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.89%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.86% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.87% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.35%\n",
      "Epoch: 173 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.144 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.167 | Test Intent Acc: 97.87% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.92% \t Test Semantic Score: 87.35%\n",
      "Epoch: 174 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.144 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.161 | Test Slot F1 Score: 95.87% \t Test Semantic Score: 86.90%\n",
      "Epoch: 175 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.146 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.171 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 96.01% \t Test Semantic Score: 87.12%\n",
      "Epoch: 176 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 100.00%\n",
      "\tVal Intent Loss: 0.139 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.175 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.01%\n",
      "Epoch: 177 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.75% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.173 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.160 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.01%\n",
      "Epoch: 178 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.78% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.170 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.161 | Test Slot F1 Score: 95.97% \t Test Semantic Score: 87.12%\n",
      "Epoch: 179 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.140 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.81% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.94% \t Test Semantic Score: 87.01%\n",
      "Epoch: 180 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.91%\n",
      "\tVal Intent Loss: 0.134 |  Val Intent Acc: 97.80% \t Val Slot Loss: 0.047 |  Val Slot F1 Score: 97.61% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.171 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.163 | Test Slot F1 Score: 95.50% \t Test Semantic Score: 85.33%\n",
      "Epoch: 181 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.92% \t Train Semantic Score: 99.60%\n",
      "\tVal Intent Loss: 0.128 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.045 |  Val Slot F1 Score: 97.52% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.173 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.151 | Test Slot F1 Score: 95.90% \t Test Semantic Score: 87.01%\n",
      "Epoch: 182 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.96% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.80% \t Train Semantic Score: 99.22%\n",
      "\tVal Intent Loss: 0.135 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.172 | Test Intent Acc: 97.09% \t Test Slot Loss: 0.150 | Test Slot F1 Score: 95.59% \t Test Semantic Score: 85.44%\n",
      "Epoch: 183 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.006 | Train Intent Acc: 99.84% \t Train Slot Loss: 0.004 | Train Slot F1 Score: 99.70% \t Train Semantic Score: 98.82%\n",
      "\tVal Intent Loss: 0.113 |  Val Intent Acc: 98.00% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.60% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.174 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.143 | Test Slot F1 Score: 95.61% \t Test Semantic Score: 86.11%\n",
      "Epoch: 184 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.005 | Train Intent Acc: 99.87% \t Train Slot Loss: 0.005 | Train Slot F1 Score: 99.53% \t Train Semantic Score: 98.39%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.37% \t Val Semantic Score: 89.20%\n",
      "\tTest Intent Loss: 0.177 | Test Intent Acc: 97.20% \t Test Slot Loss: 0.142 | Test Slot F1 Score: 95.38% \t Test Semantic Score: 86.45%\n",
      "Epoch: 185 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.005 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.006 | Train Slot F1 Score: 99.59% \t Train Semantic Score: 98.70%\n",
      "\tVal Intent Loss: 0.158 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.044 |  Val Slot F1 Score: 97.29% \t Val Semantic Score: 89.20%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.154 | Test Slot F1 Score: 95.39% \t Test Semantic Score: 86.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.006 | Train Intent Acc: 99.89% \t Train Slot Loss: 0.002 | Train Slot F1 Score: 99.88% \t Train Semantic Score: 99.46%\n",
      "\tVal Intent Loss: 0.129 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.039 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.31% \t Test Slot Loss: 0.137 | Test Slot F1 Score: 95.64% \t Test Semantic Score: 87.23%\n",
      "Epoch: 187 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.001 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.82%\n",
      "\tVal Intent Loss: 0.143 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.167 | Test Intent Acc: 97.42% \t Test Slot Loss: 0.142 | Test Slot F1 Score: 95.81% \t Test Semantic Score: 86.90%\n",
      "Epoch: 188 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.002 | Train Intent Acc: 99.98% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.97% \t Train Semantic Score: 99.82%\n",
      "\tVal Intent Loss: 0.155 |  Val Intent Acc: 96.80% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 89.40%\n",
      "\tTest Intent Loss: 0.167 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.146 | Test Slot F1 Score: 95.76% \t Test Semantic Score: 87.12%\n",
      "Epoch: 189 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.133 |  Val Intent Acc: 97.60% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.160 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.148 | Test Slot F1 Score: 95.64% \t Test Semantic Score: 87.23%\n",
      "Epoch: 190 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.001 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.20% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.55% \t Val Semantic Score: 89.60%\n",
      "\tTest Intent Loss: 0.161 | Test Intent Acc: 97.87% \t Test Slot Loss: 0.149 | Test Slot F1 Score: 95.66% \t Test Semantic Score: 87.23%\n",
      "Epoch: 191 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.166 | Test Intent Acc: 97.65% \t Test Slot Loss: 0.152 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 87.12%\n",
      "Epoch: 192 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 100.00% \t Train Semantic Score: 99.98%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 90.20%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.152 | Test Slot F1 Score: 95.63% \t Test Semantic Score: 87.01%\n",
      "Epoch: 193 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.141 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.166 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.154 | Test Slot F1 Score: 95.71% \t Test Semantic Score: 87.01%\n",
      "Epoch: 194 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.96%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.042 |  Val Slot F1 Score: 97.66% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.154 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 87.12%\n",
      "Epoch: 195 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.143 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.72% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 87.12%\n",
      "Epoch: 196 | Time: 0m 18s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.144 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.57% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.167 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.156 | Test Slot F1 Score: 95.73% \t Test Semantic Score: 87.12%\n",
      "Epoch: 197 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.138 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.69% \t Val Semantic Score: 90.00%\n",
      "\tTest Intent Loss: 0.169 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.156 | Test Slot F1 Score: 95.73% \t Test Semantic Score: 87.01%\n",
      "Epoch: 198 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.137 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.63% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.171 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.157 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 87.01%\n",
      "Epoch: 199 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.99% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.150 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.58% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.165 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.158 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 87.01%\n",
      "Epoch: 200 | Time: 0m 17s\n",
      "\tTrain Intent Loss: 0.000 | Train Intent Acc: 100.00% \t Train Slot Loss: 0.000 | Train Slot F1 Score: 99.98% \t Train Semantic Score: 99.93%\n",
      "\tVal Intent Loss: 0.142 |  Val Intent Acc: 97.40% \t Val Slot Loss: 0.043 |  Val Slot F1 Score: 97.58% \t Val Semantic Score: 89.80%\n",
      "\tTest Intent Loss: 0.168 | Test Intent Acc: 97.76% \t Test Slot Loss: 0.159 | Test Slot F1 Score: 95.75% \t Test Semantic Score: 87.01%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 200\n",
    "EARLY_STOP_EPOCH = 25\n",
    "CLIP = 1.0\n",
    "\n",
    "embedding_dim = 1024\n",
    "num_heads = 1\n",
    "hidden_dim = 512\n",
    "edge_dim = 64\n",
    "dropout = 0.2\n",
    "\n",
    "model = Net(len(TEXT.vocab), embedding_dim, num_heads, hidden_dim,\n",
    "            edge_dim, dropout, len(INTENT_LABEL.vocab), len(SLOT_LABEL.vocab)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6, amsgrad=True)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6, amsgrad=True)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-3, amsgrad=True)\n",
    "# optimizer = RAdam(model.parameters(), weight_decay=1e-6)\n",
    "# optimizer = Ranger(model.parameters(), lr=1e-3, weight_decay=1e-6, betas=(.95,0.999), eps=1e-5)\n",
    "# optimizer = Ranger(model.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_iter), epochs=N_EPOCHS)\n",
    "# optimizer = optim.Adam([\n",
    "#     {'params': model.gru.parameters()},\n",
    "#     {'params': model.myGraph.parameters(), 'lr': 1e-5}\n",
    "# ], lr=1e-3, weight_decay=1e-6)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_intent = 0\n",
    "best_val_slot = 0\n",
    "best_val_sem_acc = 0\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_intent_loss, train_intent_acc, train_slot_loss, train_slot_f1_score, train_sem_acc = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    val_intent_loss, val_intent_acc, val_slot_loss, val_slot_f1_score,  val_sem_acc= evaluate(model, val_iter, criterion)\n",
    "    test_intent_loss, test_intent_acc, test_slot_loss, test_slot_f1_score, test_sem_acc = evaluate(model, test_iter, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Intent Loss: {train_intent_loss:.3f} | Train Intent Acc: {train_intent_acc * 100:.2f}% \\t Train Slot Loss: {train_slot_loss:.3f} | Train Slot F1 Score: {train_slot_f1_score * 100:.2f}% \\t Train Semantic Score: {train_sem_acc * 100:.2f}%')\n",
    "    print(f'\\tVal Intent Loss: {val_intent_loss:.3f} |  Val Intent Acc: {val_intent_acc * 100:.2f}% \\t Val Slot Loss: {val_slot_loss:.3f} |  Val Slot F1 Score: {val_slot_f1_score * 100:.2f}% \\t Val Semantic Score: {val_sem_acc * 100:.2f}%')\n",
    "    print(f'\\tTest Intent Loss: {test_intent_loss:.3f} | Test Intent Acc: {test_intent_acc * 100:.2f}% \\t Test Slot Loss: {test_slot_loss:.3f} | Test Slot F1 Score: {test_slot_f1_score * 100:.2f}% \\t Test Semantic Score: {test_sem_acc * 100:.2f}%')\n",
    "\n",
    "#     if val_intent_acc > best_val_intent or val_slot_f1_score > best_val_slot or val_sem_acc > best_val_semantic:\n",
    "#         test_intent_loss, test_intent_acc, test_slot_loss, test_slot_f1_score, test_sem_acc = evaluate(model, test_iter, criterion)\n",
    "        \n",
    "#         if val_intent_acc > best_val_intent:\n",
    "#             best_val_intent = val_intent_acc\n",
    "#         if val_slot_f1_score > best_val_slot:\n",
    "#             best_val_slot= val_slot_f1_score\n",
    "#         if val_sem_acc > best_val_semantic:\n",
    "#             best_val_semantic = val_sem_acc\n",
    "            \n",
    "#         best_model = model\n",
    "#         torch.save(best_model, os.path.join('/kaggle/working', \"model.pkl\"))\n",
    "#         print(f'\\tTest Intent Loss: {test_intent_loss:.3f} | Test Intent Acc: {test_intent_acc * 100:.2f}% \\t Test Slot Loss: {test_slot_loss:.3f} | Test Slot F1 Score: {test_slot_f1_score * 100:.2f}% \\t Test Semantic Score: {test_sem_acc * 100:.2f}%')\n",
    "    \n",
    "#     current_val_loss = 0.1*val_intent_loss + 0.9*val_slot_loss\n",
    "    if best_val_sem_acc < val_sem_acc:\n",
    "#         best_val_loss = current_val_loss\n",
    "        best_val_sem_acc = val_sem_acc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model, os.path.join('/storage/model', \"best_model_atis.pkl\"))\n",
    "    \n",
    "#     if epoch - best_epoch >= EARLY_STOP_EPOCH:\n",
    "#         print('---------EARLY_STOP_EPOCH--------')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(os.path.join('/storage/model', \"best_model_atis.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Epoch: 106 | Test Intent Loss: 0.15582 | Test Intent Acc: 97.53639% \t Test Slot Loss: 0.15264 | Test Slot F1 Score: 95.95906% \t Test Semantic Score: 87.23404%\n"
     ]
    }
   ],
   "source": [
    "test_intent_loss, test_intent_acc, test_slot_loss, test_slot_f1_score, test_sem_acc = evaluate(best_model, test_iter, criterion)\n",
    "print(f'\\n\\nBest Epoch: {best_epoch} | Test Intent Loss: {test_intent_loss:.5f} | Test Intent Acc: {test_intent_acc * 100:.5f}% \\t Test Slot Loss: {test_slot_loss:.5f} | Test Slot F1 Score: {test_slot_f1_score * 100:.5f}% \\t Test Semantic Score: {test_sem_acc * 100:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Epoch: 106 | Test Intent Loss: 0.2 | Test Intent Acc: 97.5% \t Test Slot Loss: 0.2 | Test Slot F1 Score: 96.0% \t Test Semantic Score: 87.2%\n"
     ]
    }
   ],
   "source": [
    "test_intent_loss, test_intent_acc, test_slot_loss, test_slot_f1_score, test_sem_acc = evaluate(best_model, test_iter, criterion)\n",
    "print(f'\\n\\nBest Epoch: {best_epoch} | Test Intent Loss: {test_intent_loss:.1f} | Test Intent Acc: {test_intent_acc * 100:.1f}% \\t Test Slot Loss: {test_slot_loss:.1f} | Test Slot F1 Score: {test_slot_f1_score * 100:.1f}% \\t Test Semantic Score: {test_sem_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
